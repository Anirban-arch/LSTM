{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "nXQ--ENl9k_u",
    "outputId": "1e8f4c67-98af-46f1-d03b-5cc6265aa17d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "\n",
    "import re\n",
    "# Tutorial about Python regular expressions: https://pymotw.com/2/re/\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "import pickle\n",
    "\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import tensorboardcolab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2e9P7qsYOxgl"
   },
   "source": [
    "**Reading Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NfKdpni-9qjd"
   },
   "outputs": [],
   "source": [
    "project_data = pd.read_csv('/content/train_data.csv')\n",
    "resource_data = pd.read_csv('/content/resources.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 150
    },
    "colab_type": "code",
    "id": "rp1vsgznPAUq",
    "outputId": "853ea942-aa58-4881-86dc-ce5bdf0deee9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data points in train data (109248, 17)\n",
      "--------------------------------------------------\n",
      "The attributes of data : ['Unnamed: 0' 'id' 'teacher_id' 'teacher_prefix' 'school_state'\n",
      " 'project_submitted_datetime' 'project_grade_category'\n",
      " 'project_subject_categories' 'project_subject_subcategories'\n",
      " 'project_title' 'project_essay_1' 'project_essay_2' 'project_essay_3'\n",
      " 'project_essay_4' 'project_resource_summary'\n",
      " 'teacher_number_of_previously_posted_projects' 'project_is_approved']\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of data points in train data\", project_data.shape)\n",
    "print('-'*50)\n",
    "print(\"The attributes of data :\", project_data.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ydGm1a4hhQ6I"
   },
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 140
    },
    "colab_type": "code",
    "id": "m82BnEW-PF58",
    "outputId": "b676fb71-8b8d-400c-c25e-9671a5804fce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data points in resource data (1541272, 4)\n",
      "['id' 'description' 'quantity' 'price']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>description</th>\n",
       "      <th>quantity</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p233245</td>\n",
       "      <td>LC652 - Lakeshore Double-Space Mobile Drying Rack</td>\n",
       "      <td>1</td>\n",
       "      <td>149.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p069063</td>\n",
       "      <td>Bouncy Bands for Desks (Blue support pipes)</td>\n",
       "      <td>3</td>\n",
       "      <td>14.95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                        description  quantity   price\n",
       "0  p233245  LC652 - Lakeshore Double-Space Mobile Drying Rack         1  149.00\n",
       "1  p069063        Bouncy Bands for Desks (Blue support pipes)         3   14.95"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Number of data points in resource data\", resource_data.shape)\n",
    "print(resource_data.columns.values)\n",
    "resource_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "Vy59EM0WlxXW",
    "outputId": "363a977d-1bfb-42aa-db3b-ce4c285d3a8d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 109248/109248 [00:00<00:00, 268852.04it/s]\n"
     ]
    }
   ],
   "source": [
    "#https://github.com/mrunal46/Donors-Choose-using-LSTM/blob/master/1_Reference_EDA.ipynb\n",
    "\n",
    "presence_of_the_numerical_digits = []\n",
    "for resource in tqdm(project_data['project_resource_summary']):\n",
    "    number = []\n",
    "    for data in resource.split():\n",
    "        if data.isdigit():\n",
    "            number.append(data)\n",
    "        else:\n",
    "            pass\n",
    "    presence_of_the_numerical_digits.append(len(number))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 501
    },
    "colab_type": "code",
    "id": "KiltrHTel3qx",
    "outputId": "077f7c95-0e39-44f7-ed91-48d7ac685ccf"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>teacher_id</th>\n",
       "      <th>teacher_prefix</th>\n",
       "      <th>school_state</th>\n",
       "      <th>project_submitted_datetime</th>\n",
       "      <th>project_grade_category</th>\n",
       "      <th>project_subject_categories</th>\n",
       "      <th>project_subject_subcategories</th>\n",
       "      <th>project_title</th>\n",
       "      <th>project_essay_1</th>\n",
       "      <th>project_essay_2</th>\n",
       "      <th>project_essay_3</th>\n",
       "      <th>project_essay_4</th>\n",
       "      <th>project_resource_summary</th>\n",
       "      <th>teacher_number_of_previously_posted_projects</th>\n",
       "      <th>project_is_approved</th>\n",
       "      <th>presence_of_the_numerical_digits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>160221</td>\n",
       "      <td>p253737</td>\n",
       "      <td>c90749f5d961ff158d4b4d1e7dc665fc</td>\n",
       "      <td>Mrs.</td>\n",
       "      <td>IN</td>\n",
       "      <td>2016-12-05 13:43:57</td>\n",
       "      <td>Grades PreK-2</td>\n",
       "      <td>Literacy &amp; Language</td>\n",
       "      <td>ESL, Literacy</td>\n",
       "      <td>Educational Support for English Learners at Home</td>\n",
       "      <td>My students are English learners that are work...</td>\n",
       "      <td>\\\"The limits of your language are the limits o...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>My students need opportunities to practice beg...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>140945</td>\n",
       "      <td>p258326</td>\n",
       "      <td>897464ce9ddc600bced1151f324dd63a</td>\n",
       "      <td>Mr.</td>\n",
       "      <td>FL</td>\n",
       "      <td>2016-10-25 09:22:10</td>\n",
       "      <td>Grades 6-8</td>\n",
       "      <td>History &amp; Civics, Health &amp; Sports</td>\n",
       "      <td>Civics &amp; Government, Team Sports</td>\n",
       "      <td>Wanted: Projector for Hungry Learners</td>\n",
       "      <td>Our students arrive to our school eager to lea...</td>\n",
       "      <td>The projector we need for our school is very c...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>My students need a projector to help with view...</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21895</td>\n",
       "      <td>p182444</td>\n",
       "      <td>3465aaf82da834c0582ebd0ef8040ca0</td>\n",
       "      <td>Ms.</td>\n",
       "      <td>AZ</td>\n",
       "      <td>2016-08-31 12:03:56</td>\n",
       "      <td>Grades 6-8</td>\n",
       "      <td>Health &amp; Sports</td>\n",
       "      <td>Health &amp; Wellness, Team Sports</td>\n",
       "      <td>Soccer Equipment for AWESOME Middle School Stu...</td>\n",
       "      <td>\\r\\n\\\"True champions aren't always the ones th...</td>\n",
       "      <td>The students on the campus come to school know...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>My students need shine guards, athletic socks,...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45</td>\n",
       "      <td>p246581</td>\n",
       "      <td>f3cb9bffbba169bef1a77b243e620b60</td>\n",
       "      <td>Mrs.</td>\n",
       "      <td>KY</td>\n",
       "      <td>2016-10-06 21:16:17</td>\n",
       "      <td>Grades PreK-2</td>\n",
       "      <td>Literacy &amp; Language, Math &amp; Science</td>\n",
       "      <td>Literacy, Mathematics</td>\n",
       "      <td>Techie Kindergarteners</td>\n",
       "      <td>I work at a unique school filled with both ESL...</td>\n",
       "      <td>My students live in high poverty conditions wi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>My students need to engage in Reading and Math...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>172407</td>\n",
       "      <td>p104768</td>\n",
       "      <td>be1f7507a41f8479dc06f047086a39ec</td>\n",
       "      <td>Mrs.</td>\n",
       "      <td>TX</td>\n",
       "      <td>2016-07-11 01:10:09</td>\n",
       "      <td>Grades PreK-2</td>\n",
       "      <td>Math &amp; Science</td>\n",
       "      <td>Mathematics</td>\n",
       "      <td>Interactive Math Tools</td>\n",
       "      <td>Our second grade classroom next year will be m...</td>\n",
       "      <td>For many students, math is a subject that does...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>My students need hands on practice in mathemat...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0       id  ... project_is_approved presence_of_the_numerical_digits\n",
       "0      160221  p253737  ...                   0                                0\n",
       "1      140945  p258326  ...                   1                                0\n",
       "2       21895  p182444  ...                   0                                0\n",
       "3          45  p246581  ...                   1                                0\n",
       "4      172407  p104768  ...                   1                                0\n",
       "\n",
       "[5 rows x 18 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_data['presence_of_the_numerical_digits'] = presence_of_the_numerical_digits\n",
    "project_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZqRzCzkjmObm"
   },
   "outputs": [],
   "source": [
    "project_data.to_csv('train_data_numeric_feature_added.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DZtOKcVPYodW"
   },
   "source": [
    "**Preprocessing Categorical Features: project_grade_category**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 100
    },
    "colab_type": "code",
    "id": "DPDsZSl3PMkT",
    "outputId": "ba2a7eb9-b541-49c6-ac71-7563d17bd9d4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Grades PreK-2    44225\n",
       "Grades 3-5       37137\n",
       "Grades 6-8       16923\n",
       "Grades 9-12      10963\n",
       "Name: project_grade_category, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_data['project_grade_category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 100
    },
    "colab_type": "code",
    "id": "lXhsHJnaYzmC",
    "outputId": "9a9e7af7-786f-4c6b-8b42-a326bc122562"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "grades_prek_2    44225\n",
       "grades_3_5       37137\n",
       "grades_6_8       16923\n",
       "grades_9_12      10963\n",
       "Name: project_grade_category, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we need to remove the spaces, replace the '-' with '_' and convert all the letters to small\n",
    "\n",
    "# https://stackoverflow.com/questions/36383821/pandas-dataframe-apply-function-to-column-strings-based-on-other-column-value\n",
    "project_data['project_grade_category'] = project_data['project_grade_category'].str.replace(' ','_')\n",
    "project_data['project_grade_category'] = project_data['project_grade_category'].str.replace('-','_')\n",
    "project_data['project_grade_category'] = project_data['project_grade_category'].str.lower()\n",
    "project_data['project_grade_category'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kko4lLejY7y2"
   },
   "source": [
    "**Preprocessing Categorical Features: project_subject_categories**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 886
    },
    "colab_type": "code",
    "id": "1_hHiZDPY-OM",
    "outputId": "48b01d48-f7dd-4af5-e7ea-5c6dab339a1f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Literacy & Language                           23655\n",
       "Math & Science                                17072\n",
       "Literacy & Language, Math & Science           14636\n",
       "Health & Sports                               10177\n",
       "Music & The Arts                               5180\n",
       "Special Needs                                  4226\n",
       "Literacy & Language, Special Needs             3961\n",
       "Applied Learning                               3771\n",
       "Math & Science, Literacy & Language            2289\n",
       "Applied Learning, Literacy & Language          2191\n",
       "History & Civics                               1851\n",
       "Math & Science, Special Needs                  1840\n",
       "Literacy & Language, Music & The Arts          1757\n",
       "Math & Science, Music & The Arts               1642\n",
       "Applied Learning, Special Needs                1467\n",
       "History & Civics, Literacy & Language          1421\n",
       "Health & Sports, Special Needs                 1391\n",
       "Warmth, Care & Hunger                          1309\n",
       "Math & Science, Applied Learning               1220\n",
       "Applied Learning, Math & Science               1052\n",
       "Literacy & Language, History & Civics           809\n",
       "Health & Sports, Literacy & Language            803\n",
       "Applied Learning, Music & The Arts              758\n",
       "Math & Science, History & Civics                652\n",
       "Literacy & Language, Applied Learning           636\n",
       "Applied Learning, Health & Sports               608\n",
       "Math & Science, Health & Sports                 414\n",
       "History & Civics, Math & Science                322\n",
       "History & Civics, Music & The Arts              312\n",
       "Special Needs, Music & The Arts                 302\n",
       "Health & Sports, Math & Science                 271\n",
       "History & Civics, Special Needs                 252\n",
       "Health & Sports, Applied Learning               192\n",
       "Applied Learning, History & Civics              178\n",
       "Health & Sports, Music & The Arts               155\n",
       "Music & The Arts, Special Needs                 138\n",
       "Literacy & Language, Health & Sports             72\n",
       "Health & Sports, History & Civics                43\n",
       "Special Needs, Health & Sports                   42\n",
       "History & Civics, Applied Learning               42\n",
       "Health & Sports, Warmth, Care & Hunger           23\n",
       "Special Needs, Warmth, Care & Hunger             23\n",
       "Music & The Arts, Health & Sports                19\n",
       "Music & The Arts, History & Civics               18\n",
       "History & Civics, Health & Sports                13\n",
       "Math & Science, Warmth, Care & Hunger            11\n",
       "Music & The Arts, Applied Learning               10\n",
       "Applied Learning, Warmth, Care & Hunger          10\n",
       "Literacy & Language, Warmth, Care & Hunger        9\n",
       "Music & The Arts, Warmth, Care & Hunger           2\n",
       "History & Civics, Warmth, Care & Hunger           1\n",
       "Name: project_subject_categories, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_data['project_subject_categories'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 886
    },
    "colab_type": "code",
    "id": "OuMuDfS4QAsH",
    "outputId": "7f274aa6-700e-4995-a744-4d420abb904c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "literacy_language                       23655\n",
       "math_science                            17072\n",
       "literacy_language_math_science          14636\n",
       "health_sports                           10177\n",
       "music_arts                               5180\n",
       "specialneeds                             4226\n",
       "literacy_language_specialneeds           3961\n",
       "appliedlearning                          3771\n",
       "math_science_literacy_language           2289\n",
       "appliedlearning_literacy_language        2191\n",
       "history_civics                           1851\n",
       "math_science_specialneeds                1840\n",
       "literacy_language_music_arts             1757\n",
       "math_science_music_arts                  1642\n",
       "appliedlearning_specialneeds             1467\n",
       "history_civics_literacy_language         1421\n",
       "health_sports_specialneeds               1391\n",
       "warmth_care_hunger                       1309\n",
       "math_science_appliedlearning             1220\n",
       "appliedlearning_math_science             1052\n",
       "literacy_language_history_civics          809\n",
       "health_sports_literacy_language           803\n",
       "appliedlearning_music_arts                758\n",
       "math_science_history_civics               652\n",
       "literacy_language_appliedlearning         636\n",
       "appliedlearning_health_sports             608\n",
       "math_science_health_sports                414\n",
       "history_civics_math_science               322\n",
       "history_civics_music_arts                 312\n",
       "specialneeds_music_arts                   302\n",
       "health_sports_math_science                271\n",
       "history_civics_specialneeds               252\n",
       "health_sports_appliedlearning             192\n",
       "appliedlearning_history_civics            178\n",
       "health_sports_music_arts                  155\n",
       "music_arts_specialneeds                   138\n",
       "literacy_language_health_sports            72\n",
       "health_sports_history_civics               43\n",
       "specialneeds_health_sports                 42\n",
       "history_civics_appliedlearning             42\n",
       "health_sports_warmth_care_hunger           23\n",
       "specialneeds_warmth_care_hunger            23\n",
       "music_arts_health_sports                   19\n",
       "music_arts_history_civics                  18\n",
       "history_civics_health_sports               13\n",
       "math_science_warmth_care_hunger            11\n",
       "music_arts_appliedlearning                 10\n",
       "appliedlearning_warmth_care_hunger         10\n",
       "literacy_language_warmth_care_hunger        9\n",
       "music_arts_warmth_care_hunger               2\n",
       "history_civics_warmth_care_hunger           1\n",
       "Name: project_subject_categories, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#emove spaces, 'the' replace '&' with '_', and ',' with '_'\n",
    "project_data['project_subject_categories'] = project_data['project_subject_categories'].str.replace(' The ','')\n",
    "project_data['project_subject_categories'] = project_data['project_subject_categories'].str.replace(' ','')\n",
    "project_data['project_subject_categories'] = project_data['project_subject_categories'].str.replace('&','_')\n",
    "project_data['project_subject_categories'] = project_data['project_subject_categories'].str.replace(',','_')\n",
    "project_data['project_subject_categories'] = project_data['project_subject_categories'].str.lower()\n",
    "project_data['project_subject_categories'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F3_RCD8UZUA2"
   },
   "source": [
    "**Preprocessing Categorical Features: teacher_prefix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 117
    },
    "colab_type": "code",
    "id": "ytlUgVPvZTSF",
    "outputId": "2fef4538-e687-4f63-c300-cef96ee1155e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mrs.       57269\n",
       "Ms.        38955\n",
       "Mr.        10648\n",
       "Teacher     2360\n",
       "Dr.           13\n",
       "Name: teacher_prefix, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_data['teacher_prefix'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 117
    },
    "colab_type": "code",
    "id": "V4jDwgW6QNqn",
    "outputId": "c5840b3f-d1cc-43e7-90e6-5b7e8cda9903"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mrs.       57272\n",
       "Ms.        38955\n",
       "Mr.        10648\n",
       "Teacher     2360\n",
       "Dr.           13\n",
       "Name: teacher_prefix, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#numbwr of missing values are very less in number, we can replace it with Mrs. as most of the projects are submitted by Mrs.\n",
    "\n",
    "project_data['teacher_prefix']=project_data['teacher_prefix'].fillna('Mrs.')\n",
    "project_data['teacher_prefix'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 117
    },
    "colab_type": "code",
    "id": "uBApHjkWQVWq",
    "outputId": "442610f6-c4a6-4d11-8a21-88f717f88906"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mrs        57272\n",
       "ms         38955\n",
       "mr         10648\n",
       "teacher     2360\n",
       "dr            13\n",
       "Name: teacher_prefix, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_data['teacher_prefix'] = project_data['teacher_prefix'].str.replace('.','')\n",
    "project_data['teacher_prefix'] = project_data['teacher_prefix'].str.lower()\n",
    "project_data['teacher_prefix'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eju9LH5cZyr3"
   },
   "source": [
    "**Preprocessing Categorical Features: project_subject_subcategories**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "CH-I-xguQZBQ",
    "outputId": "ae0153eb-c66b-4689-9375-b6aaa4b47cb9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Literacy                                        9486\n",
       "Literacy, Mathematics                           8325\n",
       "Literature & Writing, Mathematics               5923\n",
       "Literacy, Literature & Writing                  5571\n",
       "Mathematics                                     5379\n",
       "Literature & Writing                            4501\n",
       "Special Needs                                   4226\n",
       "Health & Wellness                               3583\n",
       "Applied Sciences, Mathematics                   3399\n",
       "Applied Sciences                                2492\n",
       "Literacy, Special Needs                         2440\n",
       "Gym & Fitness, Health & Wellness                2264\n",
       "ESL, Literacy                                   2234\n",
       "Visual Arts                                     2217\n",
       "Music                                           1472\n",
       "Warmth, Care & Hunger                           1309\n",
       "Literature & Writing, Special Needs             1306\n",
       "Gym & Fitness                                   1195\n",
       "Health & Wellness, Special Needs                1189\n",
       "Mathematics, Special Needs                      1187\n",
       "Environmental Science                           1079\n",
       "Team Sports                                     1061\n",
       "Applied Sciences, Environmental Science          984\n",
       "Environmental Science, Health & Life Science     964\n",
       "Music, Performing Arts                           948\n",
       "Early Development                                905\n",
       "Environmental Science, Mathematics               838\n",
       "Other                                            831\n",
       "Health & Life Science                            827\n",
       "Health & Wellness, Nutrition Education           797\n",
       "                                                ... \n",
       "College & Career Prep, Team Sports                 2\n",
       "Extracurricular, Foreign Languages                 2\n",
       "Early Development, Economics                       2\n",
       "Economics, Literature & Writing                    2\n",
       "Civics & Government, Team Sports                   2\n",
       "Applied Sciences, Warmth, Care & Hunger            2\n",
       "Economics, Nutrition Education                     1\n",
       "Parent Involvement, Team Sports                    1\n",
       "History & Geography, Warmth, Care & Hunger         1\n",
       "Gym & Fitness, Social Sciences                     1\n",
       "Economics, Other                                   1\n",
       "Civics & Government, Parent Involvement            1\n",
       "Community Service, Music                           1\n",
       "Gym & Fitness, Warmth, Care & Hunger               1\n",
       "Other, Warmth, Care & Hunger                       1\n",
       "Civics & Government, Foreign Languages             1\n",
       "Economics, Foreign Languages                       1\n",
       "Financial Literacy, Performing Arts                1\n",
       "Community Service, Gym & Fitness                   1\n",
       "Gym & Fitness, Parent Involvement                  1\n",
       "Economics, Music                                   1\n",
       "ESL, Economics                                     1\n",
       "Civics & Government, Nutrition Education           1\n",
       "ESL, Team Sports                                   1\n",
       "Parent Involvement, Warmth, Care & Hunger          1\n",
       "Extracurricular, Financial Literacy                1\n",
       "Literature & Writing, Nutrition Education          1\n",
       "Financial Literacy, Foreign Languages              1\n",
       "College & Career Prep, Warmth, Care & Hunger       1\n",
       "Community Service, Financial Literacy              1\n",
       "Name: project_subject_subcategories, Length: 401, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_data['project_subject_subcategories'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "Vr8ot8gAbPrn",
    "outputId": "f3952754-10c3-41e6-a2fb-5a7f00c53fed"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "literacy                                   9486\n",
       "literacy_mathematics                       8325\n",
       "literature_writing_mathematics             5923\n",
       "literacy_literature_writing                5571\n",
       "mathematics                                5379\n",
       "literature_writing                         4501\n",
       "specialneeds                               4226\n",
       "health_wellness                            3583\n",
       "appliedsciences_mathematics                3399\n",
       "appliedsciences                            2492\n",
       "literacy_specialneeds                      2440\n",
       "gym_fitness_health_wellness                2264\n",
       "esl_literacy                               2234\n",
       "visualarts                                 2217\n",
       "music                                      1472\n",
       "warmth_care_hunger                         1309\n",
       "literature_writing_specialneeds            1306\n",
       "gym_fitness                                1195\n",
       "health_wellness_specialneeds               1189\n",
       "mathematics_specialneeds                   1187\n",
       "environmentalscience                       1079\n",
       "teamsports                                 1061\n",
       "appliedsciences_environmentalscience        984\n",
       "environmentalscience_health_lifescience     964\n",
       "music_performingarts                        948\n",
       "earlydevelopment                            905\n",
       "environmentalscience_mathematics            838\n",
       "other                                       831\n",
       "health_lifescience                          827\n",
       "health_wellness_nutritioneducation          797\n",
       "                                           ... \n",
       "civics_government_health_wellness             2\n",
       "environmentalscience_teamsports               2\n",
       "socialsciences_teamsports                     2\n",
       "financialliteracy_health_wellness             2\n",
       "college_careerprep_teamsports                 2\n",
       "extracurricular_foreignlanguages              2\n",
       "extracurricular_financialliteracy             1\n",
       "gym_fitness_parentinvolvement                 1\n",
       "communityservice_music                        1\n",
       "parentinvolvement_teamsports                  1\n",
       "esl_economics                                 1\n",
       "financialliteracy_foreignlanguages            1\n",
       "economics_nutritioneducation                  1\n",
       "parentinvolvement_warmth_care_hunger          1\n",
       "civics_government_nutritioneducation          1\n",
       "economics_music                               1\n",
       "college_careerprep_warmth_care_hunger         1\n",
       "civics_government_foreignlanguages            1\n",
       "gym_fitness_socialsciences                    1\n",
       "communityservice_gym_fitness                  1\n",
       "communityservice_financialliteracy            1\n",
       "civics_government_parentinvolvement           1\n",
       "economics_foreignlanguages                    1\n",
       "economics_other                               1\n",
       "history_geography_warmth_care_hunger          1\n",
       "literature_writing_nutritioneducation         1\n",
       "esl_teamsports                                1\n",
       "other_warmth_care_hunger                      1\n",
       "gym_fitness_warmth_care_hunger                1\n",
       "financialliteracy_performingarts              1\n",
       "Name: project_subject_subcategories, Length: 401, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_data['project_subject_subcategories'] = project_data['project_subject_subcategories'].str.replace(' The ','')\n",
    "project_data['project_subject_subcategories'] = project_data['project_subject_subcategories'].str.replace(' ','')\n",
    "project_data['project_subject_subcategories'] = project_data['project_subject_subcategories'].str.replace('&','_')\n",
    "project_data['project_subject_subcategories'] = project_data['project_subject_subcategories'].str.replace(',','_')\n",
    "project_data['project_subject_subcategories'] = project_data['project_subject_subcategories'].str.lower()\n",
    "project_data['project_subject_subcategories'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f28XvZA4beNT"
   },
   "source": [
    "**Preprocessing Categorical Features: school_state**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 886
    },
    "colab_type": "code",
    "id": "6BD-WtmdbYWg",
    "outputId": "c949fa26-aaf3-4f69-eda8-3afd74a97879"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CA    15388\n",
       "TX     7396\n",
       "NY     7318\n",
       "FL     6185\n",
       "NC     5091\n",
       "IL     4350\n",
       "GA     3963\n",
       "SC     3936\n",
       "MI     3161\n",
       "PA     3109\n",
       "IN     2620\n",
       "MO     2576\n",
       "OH     2467\n",
       "LA     2394\n",
       "MA     2389\n",
       "WA     2334\n",
       "OK     2276\n",
       "NJ     2237\n",
       "AZ     2147\n",
       "VA     2045\n",
       "WI     1827\n",
       "AL     1762\n",
       "UT     1731\n",
       "TN     1688\n",
       "CT     1663\n",
       "MD     1514\n",
       "NV     1367\n",
       "MS     1323\n",
       "KY     1304\n",
       "OR     1242\n",
       "MN     1208\n",
       "CO     1111\n",
       "AR     1049\n",
       "ID      693\n",
       "IA      666\n",
       "KS      634\n",
       "NM      557\n",
       "DC      516\n",
       "HI      507\n",
       "ME      505\n",
       "WV      503\n",
       "NH      348\n",
       "AK      345\n",
       "DE      343\n",
       "NE      309\n",
       "SD      300\n",
       "RI      285\n",
       "MT      245\n",
       "ND      143\n",
       "WY       98\n",
       "VT       80\n",
       "Name: school_state, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_data['school_state'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 886
    },
    "colab_type": "code",
    "id": "zAPnuqDPQlEk",
    "outputId": "5fe4b9b6-f1f6-47a5-9cff-7213c5398f1e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ca    15388\n",
       "tx     7396\n",
       "ny     7318\n",
       "fl     6185\n",
       "nc     5091\n",
       "il     4350\n",
       "ga     3963\n",
       "sc     3936\n",
       "mi     3161\n",
       "pa     3109\n",
       "in     2620\n",
       "mo     2576\n",
       "oh     2467\n",
       "la     2394\n",
       "ma     2389\n",
       "wa     2334\n",
       "ok     2276\n",
       "nj     2237\n",
       "az     2147\n",
       "va     2045\n",
       "wi     1827\n",
       "al     1762\n",
       "ut     1731\n",
       "tn     1688\n",
       "ct     1663\n",
       "md     1514\n",
       "nv     1367\n",
       "ms     1323\n",
       "ky     1304\n",
       "or     1242\n",
       "mn     1208\n",
       "co     1111\n",
       "ar     1049\n",
       "id      693\n",
       "ia      666\n",
       "ks      634\n",
       "nm      557\n",
       "dc      516\n",
       "hi      507\n",
       "me      505\n",
       "wv      503\n",
       "nh      348\n",
       "ak      345\n",
       "de      343\n",
       "ne      309\n",
       "sd      300\n",
       "ri      285\n",
       "mt      245\n",
       "nd      143\n",
       "wy       98\n",
       "vt       80\n",
       "Name: school_state, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_data['school_state'] = project_data['school_state'].str.lower()\n",
    "project_data['school_state'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2wP9TaAPbyA_"
   },
   "source": [
    "**Preprocessing Categorical Features: project_title**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AVDaGcWVQrSV"
   },
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/a/47091490/4084039\n",
    "import re\n",
    "\n",
    "def decontracted(phrase):\n",
    "    # specific\n",
    "    phrase = re.sub(r\"won't\", \"will not\", phrase)\n",
    "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
    "\n",
    "    # general\n",
    "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
    "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
    "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
    "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
    "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
    "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
    "    return phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UhtpSi0pQv5v"
   },
   "outputs": [],
   "source": [
    "# https://gist.github.com/sebleier/554280\n",
    "# we are removing the words from the stop words list: 'no', 'nor', 'not'\n",
    "stopwords= ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\",\\\n",
    "            \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', \\\n",
    "            'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their',\\\n",
    "            'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', \\\n",
    "            'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', \\\n",
    "            'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', \\\n",
    "            'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after',\\\n",
    "            'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further',\\\n",
    "            'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more',\\\n",
    "            'most', 'other', 'some', 'such', 'only', 'own', 'same', 'so', 'than', 'too', 'very', \\\n",
    "            's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', \\\n",
    "            've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn',\\\n",
    "            \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn',\\\n",
    "            \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", \\\n",
    "            'won', \"won't\", 'wouldn', \"wouldn't\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 117
    },
    "colab_type": "code",
    "id": "g4IU0qUNRBAK",
    "outputId": "1a4fe420-872b-4759-9ec4-5b63f53e79db"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     Educational Support for English Learners at Home\n",
       "1                Wanted: Projector for Hungry Learners\n",
       "2    Soccer Equipment for AWESOME Middle School Stu...\n",
       "3                               Techie Kindergarteners\n",
       "4                               Interactive Math Tools\n",
       "Name: project_title, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_data['project_title'].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "colab_type": "code",
    "id": "L5HRLZJIcKFm",
    "outputId": "efe7d727-7332-4402-93df-1b4b56e8fba4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing some random titles\n",
      "9 Just For the Love of Reading--\\r\\nPure Pleasure\n",
      "34 \\\"Have A Ball!!!\\\"\n",
      "147 Who needs a Chromebook?\\r\\nWE DO!!\n"
     ]
    }
   ],
   "source": [
    "print(\"printing some random titles\")\n",
    "print(9, project_data['project_title'].values[9])\n",
    "print(34, project_data['project_title'].values[34])\n",
    "print(147, project_data['project_title'].values[147])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jTMCGpoGcOIU"
   },
   "outputs": [],
   "source": [
    "# Combining all the above Statements\n",
    "\n",
    "def preprocess_text(text_data):\n",
    "    preprocessed_text = []\n",
    "    # tqdm is for printing the status bar\n",
    "    for sentance in tqdm(text_data):\n",
    "        sent = decontracted(sentance)\n",
    "        sent = sent.replace('\\\\r', ' ')\n",
    "        sent = sent.replace('\\\\n', ' ')\n",
    "        sent = sent.replace('\\\\\"', ' ')\n",
    "        sent = re.sub('[^A-Za-z0-9]+', ' ', sent)\n",
    "        # https://gist.github.com/sebleier/554280\n",
    "        sent = ' '.join(e for e in sent.split() if e.lower() not in stopwords)\n",
    "        preprocessed_text.append(sent.lower().strip())\n",
    "    return preprocessed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "zocB4XpPcU-y",
    "outputId": "dfb843ed-ac08-4052-9869-408e8dc223e9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 109248/109248 [00:02<00:00, 42566.26it/s]\n"
     ]
    }
   ],
   "source": [
    "preprocessed_titles = preprocess_text(project_data['project_title'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "colab_type": "code",
    "id": "HPyVQIJGcaD4",
    "outputId": "ff9cb80e-7c27-405a-e8e8-d3e4bb371d8d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing some random titles\n",
      "9 love reading pure pleasure\n",
      "34 ball\n",
      "147 needs chromebook\n"
     ]
    }
   ],
   "source": [
    "print(\"printing some random titles\")\n",
    "print(9, preprocessed_titles[9])\n",
    "print(34, preprocessed_titles[34])\n",
    "print(147, preprocessed_titles[147])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H6UsDuFScfd3"
   },
   "outputs": [],
   "source": [
    "project_data['project_title'] = preprocessed_titles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OOnYIUMCck4F"
   },
   "source": [
    "**Preprocessing Categorical Features: essay**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C-vrYwNHcjao"
   },
   "outputs": [],
   "source": [
    "# merge two column text dataframe: \n",
    "project_data[\"essay\"] = project_data[\"project_essay_1\"].map(str) +\\\n",
    "                        project_data[\"project_essay_2\"].map(str) + \\\n",
    "                        project_data[\"project_essay_3\"].map(str) + \\\n",
    "                        project_data[\"project_essay_4\"].map(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 137
    },
    "colab_type": "code",
    "id": "N--jPKqqcstb",
    "outputId": "9e265f0a-34b7-4e03-dc9a-3883d8047401"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing some random essay\n",
      "9 Over 95% of my students are on free or reduced lunch.  I have a few who are homeless, but despite that, they come to school with an eagerness to learn.  My students are inquisitive eager learners who  embrace the challenge of not having great books and other resources  every day.  Many of them are not afforded the opportunity to engage with these big colorful pages of a book on a regular basis at home and they don't travel to the public library.  \\r\\nIt is my duty as a teacher to do all I can to provide each student an opportunity to succeed in every aspect of life. \\r\\nReading is Fundamental! My students will read these books over and over again while boosting their comprehension skills. These books will be used for read alouds, partner reading and for Independent reading. \\r\\nThey will engage in reading to build their \\\"Love for Reading\\\" by reading for pure enjoyment. They will be introduced to some new authors as well as some old favorites. I want my students to be ready for the 21st Century and know the pleasure of holding a good hard back book in hand. There's nothing like a good book to read!  \\r\\nMy students will soar in Reading, and more because of your consideration and generous funding contribution. This will help build stamina and prepare for 3rd grade. Thank you so much for reading our proposal!nannan\n",
      "--------------------------------------------------\n",
      "34 My students mainly come from extremely low-income families, and the majority of them come from homes where both parents work full time. Most of my students are at school from 7:30 am to 6:00 pm (2:30 to 6:00 pm in the after-school program), and they all receive free and reduced meals for breakfast and lunch. \\r\\n\\r\\n\\r\\nI want my students to feel  as comfortable in my classroom as they do at home. Many of my students take on multiple roles both at home as well as in school. They are sometimes the caretakers of younger siblings, cooks, babysitters, academics, friends, and most of all, they are developing who they are going to become as adults.  I consider it an essential part of my job to model helping others gain knowledge in a positive manner. As a result, I have a community of students who love helping each other in and outside of the classroom. They consistently look for opportunities to support each other's learning in a kind and helpful way.I am excited to be experimenting with alternative seating in my classroom this school year. Studies have shown that giving students the option of where they sit in a classroom increases focus as well as motivation.  \\r\\n\\r\\nBy allowing students choice in the classroom, they are able to explore and create in a welcoming environment. Alternative classroom seating has been experimented with more frequently in recent years. I believe (along with many others), that every child learns differently. This does not only apply to how multiplication is memorized, or a paper is written, but applies to the space in which they are asked to work. I have had students in the past ask \\\"Can I work in the library? Can I work on the carpet?\\\" My answer was always, \\\"As long as you're learning, you can work wherever you want!\\\" \\r\\n\\r\\nWith the yoga balls and the lap-desks, I will be able to increase the options for seating in my classroom and expand its imaginable space.nannan\n",
      "--------------------------------------------------\n",
      "147 My students are eager to learn and make their mark on the world.\\r\\n\\r\\nThey come from a Title 1 school and need extra love.\\r\\n\\r\\nMy fourth grade students are in a high poverty area and still come to school every day to get their education. I am trying to make it fun and educational for them so they can get the most out of their schooling. I created a caring environment for the students to bloom! They deserve the best.\\r\\nThank you!\\r\\nI am requesting 1 Chromebook to access online interventions, differentiate instruction, and get extra practice. The Chromebook will be used to supplement ELA and math instruction. Students will play ELA and math games that are engaging and fun, as well as participate in assignments online. This in turn will help my students improve their skills. Having a Chromebook in the classroom would not only allow students to use the programs at their own pace, but would ensure more students are getting adequate time to use the programs. The online programs have been especially beneficial to my students with special needs. They are able to work at their level as well as be challenged with some different materials. This is making these students more confident in their abilities.\\r\\n\\r\\nThe Chromebook would allow my students to have daily access to computers and increase their computing skills.\\r\\nThis will change their lives for the better as they become more successful in school. Having access to technology in the classroom would help bridge the achievement gap.nannan\n"
     ]
    }
   ],
   "source": [
    "print(\"printing some random essay\")\n",
    "print(9, project_data['essay'].values[9])\n",
    "print('-'*50)\n",
    "print(34, project_data['essay'].values[34])\n",
    "print('-'*50)\n",
    "print(147, project_data['essay'].values[147])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "iiNTZ0E1cxzg",
    "outputId": "b846cc91-1992-43b8-89b6-8c102c2492ba"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 109248/109248 [00:54<00:00, 1997.88it/s]\n"
     ]
    }
   ],
   "source": [
    "preprocessed_essays = preprocess_text(project_data['essay'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 137
    },
    "colab_type": "code",
    "id": "ELgWfr5ZdET8",
    "outputId": "c55cc845-3e9c-412a-f7ca-2316a0cce53d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing some random essay\n",
      "9 95 students free reduced lunch homeless despite come school eagerness learn students inquisitive eager learners embrace challenge not great books resources every day many not afforded opportunity engage big colorful pages book regular basis home not travel public library duty teacher provide student opportunity succeed every aspect life reading fundamental students read books boosting comprehension skills books used read alouds partner reading independent reading engage reading build love reading reading pure enjoyment introduced new authors well old favorites want students ready 21st century know pleasure holding good hard back book hand nothing like good book read students soar reading consideration generous funding contribution help build stamina prepare 3rd grade thank much reading proposal nannan\n",
      "--------------------------------------------------\n",
      "34 students mainly come extremely low income families majority come homes parents work full time students school 7 30 6 00 pm 2 30 6 00 pm school program receive free reduced meals breakfast lunch want students feel comfortable classroom home many students take multiple roles home well school sometimes caretakers younger siblings cooks babysitters academics friends developing going become adults consider essential part job model helping others gain knowledge positive manner result community students love helping outside classroom consistently look opportunities support learning kind helpful way excited experimenting alternative seating classroom school year studies shown giving students option sit classroom increases focus well motivation allowing students choice classroom able explore create welcoming environment alternative classroom seating experimented frequently recent years believe along many others every child learns differently not apply multiplication memorized paper written applies space asked work students past ask work library work carpet answer always long learning work wherever want yoga balls lap desks able increase options seating classroom expand imaginable space nannan\n",
      "--------------------------------------------------\n",
      "147 students eager learn make mark world come title 1 school need extra love fourth grade students high poverty area still come school every day get education trying make fun educational get schooling created caring environment students bloom deserve best thank requesting 1 chromebook access online interventions differentiate instruction get extra practice chromebook used supplement ela math instruction students play ela math games engaging fun well participate assignments online turn help students improve skills chromebook classroom would not allow students use programs pace would ensure students getting adequate time use programs online programs especially beneficial students special needs able work level well challenged different materials making students confident abilities chromebook would allow students daily access computers increase computing skills change lives better become successful school access technology classroom would help bridge achievement gap nannan\n"
     ]
    }
   ],
   "source": [
    "print(\"printing some random essay\")\n",
    "print(9, preprocessed_essays[9])\n",
    "print('-'*50)\n",
    "print(34, preprocessed_essays[34])\n",
    "print('-'*50)\n",
    "print(147, preprocessed_essays[147])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yVwNQ8n_dHe4"
   },
   "outputs": [],
   "source": [
    "project_data['essay'] = preprocessed_essays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kWNPkqBadNqO"
   },
   "source": [
    "**Preprocessing Numerical Values: price**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 107
    },
    "colab_type": "code",
    "id": "cV9zUBKQdMZn",
    "outputId": "427a89eb-2802-45bb-aa51-9aa3608b7fe2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>price</th>\n",
       "      <th>quantity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p000001</td>\n",
       "      <td>459.56</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p000002</td>\n",
       "      <td>515.89</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id   price  quantity\n",
       "0  p000001  459.56         7\n",
       "1  p000002  515.89        21"
      ]
     },
     "execution_count": 33,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#https://stackoverflow.com/questions/22407798/how-to-reset-a-dataframes-indexes-for-all-groups-in-one-step\n",
    "price_data = resource_data.groupby('id').agg({'price':'sum', 'quantity':'sum'}).reset_index()\n",
    "price_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-9OyCTT6d03v"
   },
   "outputs": [],
   "source": [
    "# join two dataframes in python: \n",
    "project_data = pd.merge(project_data, price_data, on='id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 117
    },
    "colab_type": "code",
    "id": "ToElL_jFd4P6",
    "outputId": "7bd689eb-e3f2-42e6-c4ff-473ee44a684b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    154.60\n",
       "1    299.00\n",
       "2    516.85\n",
       "3    232.90\n",
       "4     67.98\n",
       "Name: price, dtype: float64"
      ]
     },
     "execution_count": 35,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_data['price'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MWmwr1h4oADU"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('/content/train_data_numeric_feature_added.csv')\n",
    "project_data['presence_of_the_numerical_digits'] = data['presence_of_the_numerical_digits']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 651
    },
    "colab_type": "code",
    "id": "84nS7aXmd7sI",
    "outputId": "952d04fa-250b-432c-a551-2764201249c1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>teacher_id</th>\n",
       "      <th>teacher_prefix</th>\n",
       "      <th>school_state</th>\n",
       "      <th>project_submitted_datetime</th>\n",
       "      <th>project_grade_category</th>\n",
       "      <th>project_subject_categories</th>\n",
       "      <th>project_subject_subcategories</th>\n",
       "      <th>project_title</th>\n",
       "      <th>project_essay_1</th>\n",
       "      <th>project_essay_2</th>\n",
       "      <th>project_essay_3</th>\n",
       "      <th>project_essay_4</th>\n",
       "      <th>project_resource_summary</th>\n",
       "      <th>teacher_number_of_previously_posted_projects</th>\n",
       "      <th>project_is_approved</th>\n",
       "      <th>presence_of_the_numerical_digits</th>\n",
       "      <th>essay</th>\n",
       "      <th>price</th>\n",
       "      <th>quantity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p253737</td>\n",
       "      <td>c90749f5d961ff158d4b4d1e7dc665fc</td>\n",
       "      <td>mrs</td>\n",
       "      <td>in</td>\n",
       "      <td>2016-12-05 13:43:57</td>\n",
       "      <td>grades_prek_2</td>\n",
       "      <td>literacy_language</td>\n",
       "      <td>esl_literacy</td>\n",
       "      <td>educational support english learners home</td>\n",
       "      <td>My students are English learners that are work...</td>\n",
       "      <td>\\\"The limits of your language are the limits o...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>My students need opportunities to practice beg...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>students english learners working english seco...</td>\n",
       "      <td>154.60</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p258326</td>\n",
       "      <td>897464ce9ddc600bced1151f324dd63a</td>\n",
       "      <td>mr</td>\n",
       "      <td>fl</td>\n",
       "      <td>2016-10-25 09:22:10</td>\n",
       "      <td>grades_6_8</td>\n",
       "      <td>history_civics_health_sports</td>\n",
       "      <td>civics_government_teamsports</td>\n",
       "      <td>wanted projector hungry learners</td>\n",
       "      <td>Our students arrive to our school eager to lea...</td>\n",
       "      <td>The projector we need for our school is very c...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>My students need a projector to help with view...</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>students arrive school eager learn polite gene...</td>\n",
       "      <td>299.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p182444</td>\n",
       "      <td>3465aaf82da834c0582ebd0ef8040ca0</td>\n",
       "      <td>ms</td>\n",
       "      <td>az</td>\n",
       "      <td>2016-08-31 12:03:56</td>\n",
       "      <td>grades_6_8</td>\n",
       "      <td>health_sports</td>\n",
       "      <td>health_wellness_teamsports</td>\n",
       "      <td>soccer equipment awesome middle school students</td>\n",
       "      <td>\\r\\n\\\"True champions aren't always the ones th...</td>\n",
       "      <td>The students on the campus come to school know...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>My students need shine guards, athletic socks,...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>true champions not always ones win guts mia ha...</td>\n",
       "      <td>516.85</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p246581</td>\n",
       "      <td>f3cb9bffbba169bef1a77b243e620b60</td>\n",
       "      <td>mrs</td>\n",
       "      <td>ky</td>\n",
       "      <td>2016-10-06 21:16:17</td>\n",
       "      <td>grades_prek_2</td>\n",
       "      <td>literacy_language_math_science</td>\n",
       "      <td>literacy_mathematics</td>\n",
       "      <td>techie kindergarteners</td>\n",
       "      <td>I work at a unique school filled with both ESL...</td>\n",
       "      <td>My students live in high poverty conditions wi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>My students need to engage in Reading and Math...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>work unique school filled esl english second l...</td>\n",
       "      <td>232.90</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p104768</td>\n",
       "      <td>be1f7507a41f8479dc06f047086a39ec</td>\n",
       "      <td>mrs</td>\n",
       "      <td>tx</td>\n",
       "      <td>2016-07-11 01:10:09</td>\n",
       "      <td>grades_prek_2</td>\n",
       "      <td>math_science</td>\n",
       "      <td>mathematics</td>\n",
       "      <td>interactive math tools</td>\n",
       "      <td>Our second grade classroom next year will be m...</td>\n",
       "      <td>For many students, math is a subject that does...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>My students need hands on practice in mathemat...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>second grade classroom next year made around 2...</td>\n",
       "      <td>67.98</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                        teacher_id  ...   price quantity\n",
       "0  p253737  c90749f5d961ff158d4b4d1e7dc665fc  ...  154.60       23\n",
       "1  p258326  897464ce9ddc600bced1151f324dd63a  ...  299.00        1\n",
       "2  p182444  3465aaf82da834c0582ebd0ef8040ca0  ...  516.85       22\n",
       "3  p246581  f3cb9bffbba169bef1a77b243e620b60  ...  232.90        4\n",
       "4  p104768  be1f7507a41f8479dc06f047086a39ec  ...   67.98        4\n",
       "\n",
       "[5 rows x 20 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_data.drop(['Unnamed: 0'], axis = 1, inplace = True)\n",
    "project_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PBiLYQDveZAx"
   },
   "outputs": [],
   "source": [
    "project_data.to_csv(\"processed_train_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-5-AZLL5DDuh"
   },
   "outputs": [],
   "source": [
    "#importing all the required lib\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import os\n",
    "import math\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import SpatialDropout1D, LSTM, BatchNormalization,concatenate,Flatten,Embedding,Dense,Dropout,MaxPooling2D,Reshape,CuDNNLSTM\n",
    "from keras.models import Sequential\n",
    "from keras import Model,Input\n",
    "from keras.layers.convolutional import Conv2D,Conv1D\n",
    "import keras.backend as k\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from sklearn.utils import compute_class_weight\n",
    "from keras.initializers import he_normal,glorot_normal\n",
    "from keras.regularizers import l1,l2\n",
    "from keras.callbacks import Callback, EarlyStopping, ModelCheckpoint,LearningRateScheduler\n",
    "from time import time\n",
    "from tensorflow.python.keras.callbacks import TensorBoard\n",
    "from IPython.display import SVG, display\n",
    "import pickle \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nIys3wxzHFkV"
   },
   "outputs": [],
   "source": [
    "dbfile = open('/content/glove_vectors', 'rb')      \n",
    "db = pickle.load(dbfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "ETZ3QxwdiCO0",
    "outputId": "43641443-f6b2-44eb-c0e5-0babb0907fb2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(109248, 21)"
      ]
     },
     "execution_count": 41,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#REading the dataset\n",
    "project_data = pd.read_csv('/content/processed_train_data.csv')\n",
    "project_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 328
    },
    "colab_type": "code",
    "id": "gd32WcUEC7wT",
    "outputId": "46e98f49-e413-4b38-8402-2f3709a197e9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>teacher_id</th>\n",
       "      <th>teacher_prefix</th>\n",
       "      <th>school_state</th>\n",
       "      <th>project_submitted_datetime</th>\n",
       "      <th>project_grade_category</th>\n",
       "      <th>project_subject_categories</th>\n",
       "      <th>project_subject_subcategories</th>\n",
       "      <th>project_title</th>\n",
       "      <th>project_essay_1</th>\n",
       "      <th>project_essay_2</th>\n",
       "      <th>project_essay_3</th>\n",
       "      <th>project_essay_4</th>\n",
       "      <th>project_resource_summary</th>\n",
       "      <th>teacher_number_of_previously_posted_projects</th>\n",
       "      <th>project_is_approved</th>\n",
       "      <th>presence_of_the_numerical_digits</th>\n",
       "      <th>essay</th>\n",
       "      <th>price</th>\n",
       "      <th>quantity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>p253737</td>\n",
       "      <td>c90749f5d961ff158d4b4d1e7dc665fc</td>\n",
       "      <td>mrs</td>\n",
       "      <td>in</td>\n",
       "      <td>2016-12-05 13:43:57</td>\n",
       "      <td>grades_prek_2</td>\n",
       "      <td>literacy_language</td>\n",
       "      <td>esl_literacy</td>\n",
       "      <td>educational support english learners home</td>\n",
       "      <td>My students are English learners that are work...</td>\n",
       "      <td>\\\"The limits of your language are the limits o...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>My students need opportunities to practice beg...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>students english learners working english seco...</td>\n",
       "      <td>154.6</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>p258326</td>\n",
       "      <td>897464ce9ddc600bced1151f324dd63a</td>\n",
       "      <td>mr</td>\n",
       "      <td>fl</td>\n",
       "      <td>2016-10-25 09:22:10</td>\n",
       "      <td>grades_6_8</td>\n",
       "      <td>history_civics_health_sports</td>\n",
       "      <td>civics_government_teamsports</td>\n",
       "      <td>wanted projector hungry learners</td>\n",
       "      <td>Our students arrive to our school eager to lea...</td>\n",
       "      <td>The projector we need for our school is very c...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>My students need a projector to help with view...</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>students arrive school eager learn polite gene...</td>\n",
       "      <td>299.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0       id  ...  price quantity\n",
       "0           0  p253737  ...  154.6       23\n",
       "1           1  p258326  ...  299.0        1\n",
       "\n",
       "[2 rows x 21 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MowzOHrZpARz"
   },
   "outputs": [],
   "source": [
    "#merging teacher number of previouly posted projects, presence of the numerical digits, price and quantity into a single feature\n",
    "project_data.drop(['Unnamed: 0'], axis =1 , inplace = True)\n",
    "class_label = project_data['project_is_approved']\n",
    "project_data['remaining_input'] = project_data['teacher_number_of_previously_posted_projects']  +\\\n",
    "                                    project_data['presence_of_the_numerical_digits']  + \\\n",
    "                                    project_data['price'] + project_data['quantity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hq4K2Rc9pIrc"
   },
   "outputs": [],
   "source": [
    "project_data['total_txt'] = project_data['project_title'] + ' ' + project_data['essay'] + ' ' + project_data['project_resource_summary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TsU8fEbgpOak"
   },
   "outputs": [],
   "source": [
    "project_data.replace(to_replace=np.NaN, value= str('nan'),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 167
    },
    "colab_type": "code",
    "id": "W9x8YB_TpSW5",
    "outputId": "cf3cb8d7-fea0-4b15-ab50-566dd2b3f635"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'teacher_id', 'teacher_prefix', 'school_state',\n",
       "       'project_submitted_datetime', 'project_grade_category',\n",
       "       'project_subject_categories', 'project_subject_subcategories',\n",
       "       'project_title', 'project_essay_1', 'project_essay_2',\n",
       "       'project_essay_3', 'project_essay_4', 'project_resource_summary',\n",
       "       'teacher_number_of_previously_posted_projects', 'project_is_approved',\n",
       "       'presence_of_the_numerical_digits', 'essay', 'price', 'quantity',\n",
       "       'remaining_input', 'total_txt'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 46,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col = project_data.columns\n",
    "col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "thdbdGxqpXj0"
   },
   "outputs": [],
   "source": [
    "col = ['id','teacher_id','project_submitted_datetime','project_title','project_essay_1', 'project_essay_2',\n",
    "       'project_essay_3', 'project_essay_4','project_resource_summary',\n",
    "       'teacher_number_of_previously_posted_projects', 'project_is_approved','price', 'quantity',\n",
    "        'presence_of_the_numerical_digits','essay']\n",
    "\n",
    "project_data.drop(labels=col,axis =1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AvckPkViJyTZ"
   },
   "outputs": [],
   "source": [
    "col = project_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TH1WrRCvpg9j"
   },
   "outputs": [],
   "source": [
    "col = ['teacher_prefix', 'school_state', 'project_grade_category',\n",
    "       'project_subject_categories', 'project_subject_subcategories','total_txt',\n",
    "       'remaining_input']\n",
    "project_data = project_data[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rHd4skbhJLOM"
   },
   "outputs": [],
   "source": [
    "def word_ranking(dataframe):\n",
    "    col_names = dataframe.columns\n",
    "    features = []\n",
    "    #performing train test split\n",
    "    train,test,y_train,y_test = train_test_split(dataframe, class_label , stratify = class_label, train_size = 0.7)\n",
    "\n",
    "    train,cv,y_train,y_cv = train_test_split(train,y_train,stratify = y_train,train_size = 0.8)\n",
    "    for col in col_names[:6]:\n",
    "        print(col)\n",
    "        bag_of_words = CountVectorizer(lowercase= False)\n",
    "        bow_words = bag_of_words.fit_transform(train[col])\n",
    "        print(bow_words.shape)\n",
    "        \n",
    "        #Lets now store the document term matrix in a dictionary.\n",
    "        freqs = bow_words.sum(axis=0).A1\n",
    "        index = freqs.argsort()\n",
    "        words = bag_of_words.get_feature_names()\n",
    "        \n",
    "        \n",
    "\n",
    "        # Assigning Rank to each word based on its freq of occurance. Word with highest freq is assigned rank 1 \n",
    "        word_rank = dict()\n",
    "        rank = 1\n",
    "        for i in index[::-1]:\n",
    "            k = words[i]\n",
    "            word_rank[k] = rank\n",
    "            rank+=1\n",
    "        features.append(word_rank)\n",
    "        \n",
    "        #Every word in each review is replaced by its rank\n",
    "        rank = [] # list of all the review with words replaced with rank\n",
    "        for sent in train[col].values:\n",
    "            txt_row = []\n",
    "            for word in sent.split():\n",
    "                if word in word_rank.keys():\n",
    "                    txt_row.append(word_rank[word])\n",
    "                else:\n",
    "                    pass\n",
    "            rank.append(txt_row)\n",
    "        \n",
    "        train[col] = rank\n",
    "        \n",
    "        rank = [] # list of all the review with words replaced with rank\n",
    "        for sent in test[col].values:\n",
    "            txt_row = []\n",
    "            for word in sent.split():\n",
    "                if word in word_rank.keys():\n",
    "                    txt_row.append(word_rank[word])\n",
    "                else:\n",
    "                    pass\n",
    "            rank.append(txt_row)\n",
    "        \n",
    "        test[col] = rank\n",
    "        \n",
    "        rank = [] # list of all the review with words replaced with rank\n",
    "        for sent in cv[col].values:\n",
    "            txt_row = []\n",
    "            for word in sent.split():\n",
    "                if word in word_rank.keys():\n",
    "                    txt_row.append(word_rank[word])\n",
    "                else:\n",
    "                    pass\n",
    "            rank.append(txt_row)\n",
    "        \n",
    "        cv[col] = rank\n",
    "    return train,test,cv,y_train,y_test,y_cv,features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 217
    },
    "colab_type": "code",
    "id": "mp-BmexRJjWj",
    "outputId": "42916331-592e-42bf-ddea-8cb655155ba2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "teacher_prefix\n",
      "(61178, 5)\n",
      "school_state\n",
      "(61178, 51)\n",
      "project_grade_category\n",
      "(61178, 4)\n",
      "project_subject_categories\n",
      "(61178, 51)\n",
      "project_subject_subcategories\n",
      "(61178, 380)\n",
      "total_txt\n",
      "(61178, 56870)\n"
     ]
    }
   ],
   "source": [
    "train,test,cv,y_train,y_test,y_cv,feature_names = word_ranking(project_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "id": "9iZ3HKOpKVLE",
    "outputId": "f3bfa766-bc6d-4e11-e189-99f01ed8259b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the Train dataset:  61178\n",
      "Shape of the Test dataset:  32775\n",
      "Shape of the cv dataset: 15295\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of the Train dataset: \", train.shape[0])\n",
    "print(\"Shape of the Test dataset: \", test.shape[0])\n",
    "print(\"Shape of the cv dataset:\", cv.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ii5M3fE0KdsX"
   },
   "outputs": [],
   "source": [
    "#converting class labels to categorical variables\n",
    "from keras.utils import to_categorical\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "y_cv = to_categorical(y_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HcdeUWwdLLh1"
   },
   "outputs": [],
   "source": [
    "class_wght = compute_class_weight(\"balanced\", classes= np.unique(class_label),y=class_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "PzoC7-CJLXcM",
    "outputId": "d5275f2e-341b-4832-b397-9ecf72cdba53"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.30214001, 0.58921753])"
      ]
     },
     "execution_count": 55,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_wght"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "xo0GP2D7FEW-",
    "outputId": "19e32364-9db7-4631-8f71-521b9d07feea"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'appliedsciences': 11,\n",
       " 'appliedsciences_charactereducation': 152,\n",
       " 'appliedsciences_civics_government': 268,\n",
       " 'appliedsciences_college_careerprep': 49,\n",
       " 'appliedsciences_communityservice': 237,\n",
       " 'appliedsciences_earlydevelopment': 84,\n",
       " 'appliedsciences_economics': 328,\n",
       " 'appliedsciences_environmentalscience': 23,\n",
       " 'appliedsciences_esl': 120,\n",
       " 'appliedsciences_extracurricular': 87,\n",
       " 'appliedsciences_financialliteracy': 326,\n",
       " 'appliedsciences_foreignlanguages': 299,\n",
       " 'appliedsciences_gym_fitness': 212,\n",
       " 'appliedsciences_health_lifescience': 38,\n",
       " 'appliedsciences_health_wellness': 153,\n",
       " 'appliedsciences_history_geography': 114,\n",
       " 'appliedsciences_literacy': 39,\n",
       " 'appliedsciences_literature_writing': 48,\n",
       " 'appliedsciences_mathematics': 9,\n",
       " 'appliedsciences_music': 130,\n",
       " 'appliedsciences_nutritioneducation': 316,\n",
       " 'appliedsciences_other': 109,\n",
       " 'appliedsciences_parentinvolvement': 138,\n",
       " 'appliedsciences_performingarts': 181,\n",
       " 'appliedsciences_socialsciences': 143,\n",
       " 'appliedsciences_specialneeds': 59,\n",
       " 'appliedsciences_teamsports': 248,\n",
       " 'appliedsciences_visualarts': 35,\n",
       " 'appliedsciences_warmth_care_hunger': 322,\n",
       " 'charactereducation': 54,\n",
       " 'charactereducation_civics_government': 374,\n",
       " 'charactereducation_college_careerprep': 105,\n",
       " 'charactereducation_communityservice': 146,\n",
       " 'charactereducation_earlydevelopment': 90,\n",
       " 'charactereducation_economics': 372,\n",
       " 'charactereducation_environmentalscience': 207,\n",
       " 'charactereducation_esl': 203,\n",
       " 'charactereducation_extracurricular': 142,\n",
       " 'charactereducation_financialliteracy': 278,\n",
       " 'charactereducation_foreignlanguages': 266,\n",
       " 'charactereducation_gym_fitness': 305,\n",
       " 'charactereducation_health_lifescience': 197,\n",
       " 'charactereducation_health_wellness': 108,\n",
       " 'charactereducation_history_geography': 264,\n",
       " 'charactereducation_literacy': 60,\n",
       " 'charactereducation_literature_writing': 91,\n",
       " 'charactereducation_mathematics': 115,\n",
       " 'charactereducation_music': 209,\n",
       " 'charactereducation_nutritioneducation': 321,\n",
       " 'charactereducation_other': 113,\n",
       " 'charactereducation_parentinvolvement': 183,\n",
       " 'charactereducation_performingarts': 251,\n",
       " 'charactereducation_socialsciences': 215,\n",
       " 'charactereducation_specialneeds': 80,\n",
       " 'charactereducation_teamsports': 206,\n",
       " 'charactereducation_visualarts': 124,\n",
       " 'charactereducation_warmth_care_hunger': 304,\n",
       " 'civics_government': 132,\n",
       " 'civics_government_college_careerprep': 254,\n",
       " 'civics_government_communityservice': 275,\n",
       " 'civics_government_economics': 219,\n",
       " 'civics_government_environmentalscience': 223,\n",
       " 'civics_government_esl': 332,\n",
       " 'civics_government_extracurricular': 366,\n",
       " 'civics_government_financialliteracy': 236,\n",
       " 'civics_government_foreignlanguages': 367,\n",
       " 'civics_government_health_lifescience': 238,\n",
       " 'civics_government_health_wellness': 369,\n",
       " 'civics_government_history_geography': 73,\n",
       " 'civics_government_literacy': 93,\n",
       " 'civics_government_literature_writing': 122,\n",
       " 'civics_government_mathematics': 252,\n",
       " 'civics_government_parentinvolvement': 371,\n",
       " 'civics_government_performingarts': 333,\n",
       " 'civics_government_socialsciences': 134,\n",
       " 'civics_government_specialneeds': 201,\n",
       " 'civics_government_teamsports': 373,\n",
       " 'civics_government_visualarts': 253,\n",
       " 'college_careerprep': 50,\n",
       " 'college_careerprep_communityservice': 185,\n",
       " 'college_careerprep_earlydevelopment': 174,\n",
       " 'college_careerprep_economics': 289,\n",
       " 'college_careerprep_environmentalscience': 182,\n",
       " 'college_careerprep_esl': 281,\n",
       " 'college_careerprep_extracurricular': 160,\n",
       " 'college_careerprep_financialliteracy': 235,\n",
       " 'college_careerprep_foreignlanguages': 288,\n",
       " 'college_careerprep_gym_fitness': 337,\n",
       " 'college_careerprep_health_lifescience': 151,\n",
       " 'college_careerprep_health_wellness': 246,\n",
       " 'college_careerprep_history_geography': 193,\n",
       " 'college_careerprep_literacy': 71,\n",
       " 'college_careerprep_literature_writing': 61,\n",
       " 'college_careerprep_mathematics': 68,\n",
       " 'college_careerprep_music': 247,\n",
       " 'college_careerprep_nutritioneducation': 240,\n",
       " 'college_careerprep_other': 116,\n",
       " 'college_careerprep_parentinvolvement': 186,\n",
       " 'college_careerprep_performingarts': 202,\n",
       " 'college_careerprep_socialsciences': 173,\n",
       " 'college_careerprep_specialneeds': 98,\n",
       " 'college_careerprep_visualarts': 101,\n",
       " 'college_careerprep_warmth_care_hunger': 352,\n",
       " 'communityservice': 150,\n",
       " 'communityservice_earlydevelopment': 282,\n",
       " 'communityservice_economics': 336,\n",
       " 'communityservice_environmentalscience': 170,\n",
       " 'communityservice_esl': 339,\n",
       " 'communityservice_extracurricular': 231,\n",
       " 'communityservice_financialliteracy': 361,\n",
       " 'communityservice_health_lifescience': 286,\n",
       " 'communityservice_health_wellness': 226,\n",
       " 'communityservice_history_geography': 300,\n",
       " 'communityservice_literacy': 249,\n",
       " 'communityservice_literature_writing': 189,\n",
       " 'communityservice_mathematics': 227,\n",
       " 'communityservice_nutritioneducation': 302,\n",
       " 'communityservice_other': 250,\n",
       " 'communityservice_parentinvolvement': 270,\n",
       " 'communityservice_socialsciences': 277,\n",
       " 'communityservice_specialneeds': 234,\n",
       " 'communityservice_visualarts': 178,\n",
       " 'earlydevelopment': 27,\n",
       " 'earlydevelopment_environmentalscience': 140,\n",
       " 'earlydevelopment_extracurricular': 230,\n",
       " 'earlydevelopment_financialliteracy': 331,\n",
       " 'earlydevelopment_foreignlanguages': 346,\n",
       " 'earlydevelopment_gym_fitness': 169,\n",
       " 'earlydevelopment_health_lifescience': 159,\n",
       " 'earlydevelopment_health_wellness': 63,\n",
       " 'earlydevelopment_history_geography': 347,\n",
       " 'earlydevelopment_literacy': 31,\n",
       " 'earlydevelopment_literature_writing': 75,\n",
       " 'earlydevelopment_mathematics': 67,\n",
       " 'earlydevelopment_music': 213,\n",
       " 'earlydevelopment_nutritioneducation': 269,\n",
       " 'earlydevelopment_other': 99,\n",
       " 'earlydevelopment_parentinvolvement': 162,\n",
       " 'earlydevelopment_performingarts': 229,\n",
       " 'earlydevelopment_socialsciences': 220,\n",
       " 'earlydevelopment_specialneeds': 30,\n",
       " 'earlydevelopment_teamsports': 350,\n",
       " 'earlydevelopment_visualarts': 83,\n",
       " 'earlydevelopment_warmth_care_hunger': 356,\n",
       " 'economics': 166,\n",
       " 'economics_environmentalscience': 301,\n",
       " 'economics_financialliteracy': 129,\n",
       " 'economics_health_lifescience': 345,\n",
       " 'economics_history_geography': 179,\n",
       " 'economics_literacy': 265,\n",
       " 'economics_literature_writing': 349,\n",
       " 'economics_mathematics': 205,\n",
       " 'economics_nutritioneducation': 358,\n",
       " 'economics_socialsciences': 241,\n",
       " 'economics_specialneeds': 355,\n",
       " 'economics_visualarts': 298,\n",
       " 'environmentalscience': 22,\n",
       " 'environmentalscience_extracurricular': 218,\n",
       " 'environmentalscience_financialliteracy': 297,\n",
       " 'environmentalscience_foreignlanguages': 296,\n",
       " 'environmentalscience_gym_fitness': 312,\n",
       " 'environmentalscience_health_lifescience': 25,\n",
       " 'environmentalscience_health_wellness': 147,\n",
       " 'environmentalscience_history_geography': 89,\n",
       " 'environmentalscience_literacy': 47,\n",
       " 'environmentalscience_literature_writing': 70,\n",
       " 'environmentalscience_mathematics': 28,\n",
       " 'environmentalscience_music': 313,\n",
       " 'environmentalscience_nutritioneducation': 164,\n",
       " 'environmentalscience_other': 258,\n",
       " 'environmentalscience_parentinvolvement': 263,\n",
       " 'environmentalscience_performingarts': 257,\n",
       " 'environmentalscience_socialsciences': 126,\n",
       " 'environmentalscience_specialneeds': 86,\n",
       " 'environmentalscience_visualarts': 77,\n",
       " 'environmentalscience_warmth_care_hunger': 343,\n",
       " 'esl': 46,\n",
       " 'esl_earlydevelopment': 123,\n",
       " 'esl_economics': 363,\n",
       " 'esl_environmentalscience': 157,\n",
       " 'esl_extracurricular': 334,\n",
       " 'esl_financialliteracy': 308,\n",
       " 'esl_foreignlanguages': 135,\n",
       " 'esl_gym_fitness': 364,\n",
       " 'esl_health_lifescience': 171,\n",
       " 'esl_health_wellness': 217,\n",
       " 'esl_history_geography': 187,\n",
       " 'esl_literacy': 13,\n",
       " 'esl_literature_writing': 33,\n",
       " 'esl_mathematics': 65,\n",
       " 'esl_music': 216,\n",
       " 'esl_nutritioneducation': 379,\n",
       " 'esl_other': 204,\n",
       " 'esl_parentinvolvement': 244,\n",
       " 'esl_performingarts': 211,\n",
       " 'esl_socialsciences': 243,\n",
       " 'esl_specialneeds': 76,\n",
       " 'esl_teamsports': 380,\n",
       " 'esl_visualarts': 163,\n",
       " 'extracurricular': 104,\n",
       " 'extracurricular_financialliteracy': 377,\n",
       " 'extracurricular_foreignlanguages': 338,\n",
       " 'extracurricular_gym_fitness': 318,\n",
       " 'extracurricular_health_lifescience': 319,\n",
       " 'extracurricular_health_wellness': 242,\n",
       " 'extracurricular_history_geography': 320,\n",
       " 'extracurricular_literacy': 165,\n",
       " 'extracurricular_literature_writing': 184,\n",
       " 'extracurricular_mathematics': 137,\n",
       " 'extracurricular_music': 190,\n",
       " 'extracurricular_nutritioneducation': 340,\n",
       " 'extracurricular_other': 177,\n",
       " 'extracurricular_parentinvolvement': 341,\n",
       " 'extracurricular_performingarts': 195,\n",
       " 'extracurricular_socialsciences': 342,\n",
       " 'extracurricular_specialneeds': 208,\n",
       " 'extracurricular_teamsports': 191,\n",
       " 'extracurricular_visualarts': 117,\n",
       " 'financialliteracy': 94,\n",
       " 'financialliteracy_history_geography': 221,\n",
       " 'financialliteracy_literacy': 192,\n",
       " 'financialliteracy_literature_writing': 276,\n",
       " 'financialliteracy_mathematics': 97,\n",
       " 'financialliteracy_other': 348,\n",
       " 'financialliteracy_socialsciences': 344,\n",
       " 'financialliteracy_specialneeds': 155,\n",
       " 'financialliteracy_visualarts': 292,\n",
       " 'foreignlanguages': 57,\n",
       " 'foreignlanguages_gym_fitness': 370,\n",
       " 'foreignlanguages_health_lifescience': 368,\n",
       " 'foreignlanguages_health_wellness': 280,\n",
       " 'foreignlanguages_history_geography': 224,\n",
       " 'foreignlanguages_literacy': 72,\n",
       " 'foreignlanguages_literature_writing': 133,\n",
       " 'foreignlanguages_mathematics': 161,\n",
       " 'foreignlanguages_music': 262,\n",
       " 'foreignlanguages_other': 295,\n",
       " 'foreignlanguages_performingarts': 307,\n",
       " 'foreignlanguages_socialsciences': 279,\n",
       " 'foreignlanguages_specialneeds': 210,\n",
       " 'foreignlanguages_visualarts': 222,\n",
       " 'gym_fitness': 20,\n",
       " 'gym_fitness_health_lifescience': 256,\n",
       " 'gym_fitness_health_wellness': 14,\n",
       " 'gym_fitness_history_geography': 306,\n",
       " 'gym_fitness_literacy': 188,\n",
       " 'gym_fitness_literature_writing': 225,\n",
       " 'gym_fitness_mathematics': 180,\n",
       " 'gym_fitness_music': 194,\n",
       " 'gym_fitness_nutritioneducation': 136,\n",
       " 'gym_fitness_other': 287,\n",
       " 'gym_fitness_parentinvolvement': 365,\n",
       " 'gym_fitness_performingarts': 271,\n",
       " 'gym_fitness_socialsciences': 378,\n",
       " 'gym_fitness_specialneeds': 81,\n",
       " 'gym_fitness_teamsports': 36,\n",
       " 'gym_fitness_visualarts': 228,\n",
       " 'gym_fitness_warmth_care_hunger': 362,\n",
       " 'health_lifescience': 26,\n",
       " 'health_lifescience_health_wellness': 92,\n",
       " 'health_lifescience_history_geography': 144,\n",
       " 'health_lifescience_literacy': 56,\n",
       " 'health_lifescience_literature_writing': 78,\n",
       " 'health_lifescience_mathematics': 41,\n",
       " 'health_lifescience_music': 293,\n",
       " 'health_lifescience_nutritioneducation': 139,\n",
       " 'health_lifescience_other': 260,\n",
       " 'health_lifescience_parentinvolvement': 273,\n",
       " 'health_lifescience_performingarts': 290,\n",
       " 'health_lifescience_socialsciences': 119,\n",
       " 'health_lifescience_specialneeds': 96,\n",
       " 'health_lifescience_teamsports': 284,\n",
       " 'health_lifescience_visualarts': 128,\n",
       " 'health_lifescience_warmth_care_hunger': 323,\n",
       " 'health_wellness': 8,\n",
       " 'health_wellness_history_geography': 214,\n",
       " 'health_wellness_literacy': 44,\n",
       " 'health_wellness_literature_writing': 66,\n",
       " 'health_wellness_mathematics': 74,\n",
       " 'health_wellness_music': 172,\n",
       " 'health_wellness_nutritioneducation': 32,\n",
       " 'health_wellness_other': 82,\n",
       " 'health_wellness_parentinvolvement': 309,\n",
       " 'health_wellness_performingarts': 315,\n",
       " 'health_wellness_socialsciences': 283,\n",
       " 'health_wellness_specialneeds': 18,\n",
       " 'health_wellness_teamsports': 53,\n",
       " 'health_wellness_visualarts': 168,\n",
       " 'health_wellness_warmth_care_hunger': 232,\n",
       " 'history_geography': 43,\n",
       " 'history_geography_literacy': 42,\n",
       " 'history_geography_literature_writing': 37,\n",
       " 'history_geography_mathematics': 112,\n",
       " 'history_geography_music': 200,\n",
       " 'history_geography_other': 267,\n",
       " 'history_geography_performingarts': 272,\n",
       " 'history_geography_socialsciences': 58,\n",
       " 'history_geography_specialneeds': 107,\n",
       " 'history_geography_teamsports': 324,\n",
       " 'history_geography_visualarts': 88,\n",
       " 'history_geography_warmth_care_hunger': 375,\n",
       " 'literacy': 1,\n",
       " 'literacy_literature_writing': 4,\n",
       " 'literacy_mathematics': 2,\n",
       " 'literacy_music': 100,\n",
       " 'literacy_nutritioneducation': 291,\n",
       " 'literacy_other': 85,\n",
       " 'literacy_parentinvolvement': 95,\n",
       " 'literacy_performingarts': 103,\n",
       " 'literacy_socialsciences': 52,\n",
       " 'literacy_specialneeds': 10,\n",
       " 'literacy_teamsports': 239,\n",
       " 'literacy_visualarts': 40,\n",
       " 'literacy_warmth_care_hunger': 317,\n",
       " 'literature_writing': 6,\n",
       " 'literature_writing_mathematics': 3,\n",
       " 'literature_writing_music': 149,\n",
       " 'literature_writing_other': 102,\n",
       " 'literature_writing_parentinvolvement': 148,\n",
       " 'literature_writing_performingarts': 106,\n",
       " 'literature_writing_socialsciences': 55,\n",
       " 'literature_writing_specialneeds': 17,\n",
       " 'literature_writing_teamsports': 294,\n",
       " 'literature_writing_visualarts': 34,\n",
       " 'literature_writing_warmth_care_hunger': 310,\n",
       " 'mathematics': 5,\n",
       " 'mathematics_music': 127,\n",
       " 'mathematics_nutritioneducation': 261,\n",
       " 'mathematics_other': 111,\n",
       " 'mathematics_parentinvolvement': 125,\n",
       " 'mathematics_performingarts': 198,\n",
       " 'mathematics_socialsciences': 121,\n",
       " 'mathematics_specialneeds': 19,\n",
       " 'mathematics_teamsports': 274,\n",
       " 'mathematics_visualarts': 45,\n",
       " 'music': 15,\n",
       " 'music_parentinvolvement': 330,\n",
       " 'music_performingarts': 24,\n",
       " 'music_socialsciences': 314,\n",
       " 'music_specialneeds': 110,\n",
       " 'music_teamsports': 311,\n",
       " 'music_visualarts': 154,\n",
       " 'nutritioneducation': 69,\n",
       " 'nutritioneducation_other': 233,\n",
       " 'nutritioneducation_socialsciences': 353,\n",
       " 'nutritioneducation_specialneeds': 175,\n",
       " 'nutritioneducation_teamsports': 259,\n",
       " 'nutritioneducation_visualarts': 325,\n",
       " 'nutritioneducation_warmth_care_hunger': 354,\n",
       " 'other': 29,\n",
       " 'other_parentinvolvement': 285,\n",
       " 'other_performingarts': 360,\n",
       " 'other_socialsciences': 327,\n",
       " 'other_specialneeds': 62,\n",
       " 'other_teamsports': 357,\n",
       " 'other_visualarts': 141,\n",
       " 'parentinvolvement': 156,\n",
       " 'parentinvolvement_performingarts': 329,\n",
       " 'parentinvolvement_socialsciences': 303,\n",
       " 'parentinvolvement_specialneeds': 176,\n",
       " 'parentinvolvement_visualarts': 167,\n",
       " 'parentinvolvement_warmth_care_hunger': 351,\n",
       " 'performingarts': 51,\n",
       " 'performingarts_socialsciences': 255,\n",
       " 'performingarts_specialneeds': 196,\n",
       " 'performingarts_teamsports': 245,\n",
       " 'performingarts_visualarts': 118,\n",
       " 'socialsciences': 79,\n",
       " 'socialsciences_specialneeds': 145,\n",
       " 'socialsciences_teamsports': 376,\n",
       " 'socialsciences_visualarts': 131,\n",
       " 'specialneeds': 7,\n",
       " 'specialneeds_teamsports': 158,\n",
       " 'specialneeds_visualarts': 64,\n",
       " 'specialneeds_warmth_care_hunger': 199,\n",
       " 'teamsports': 21,\n",
       " 'teamsports_visualarts': 359,\n",
       " 'visualarts': 12,\n",
       " 'visualarts_warmth_care_hunger': 335,\n",
       " 'warmth_care_hunger': 16}"
      ]
     },
     "execution_count": 56,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0l1DbtB1Lb53"
   },
   "outputs": [],
   "source": [
    "#Creating a matrix with rows as words and columns with 50 dim vectors for each word\n",
    "def embedding_mat(word_index,embedding_dim = 300):\n",
    "    embedding_matrix = np.zeros((len(word_index) + 1, embedding_dim))\n",
    "    for word, i in word_index.items():\n",
    "        embedding_vector = db.get(word)\n",
    "        if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aTq99e_HFgZT"
   },
   "source": [
    "**Tokenizing The Text part**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 385
    },
    "colab_type": "code",
    "id": "qzUddmpcLwTl",
    "outputId": "d0ab0b26-12e8-4ef3-e01d-cc514d526196"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(61178, 250)\n",
      "[    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0   374    85   716     1   220    12   130    91   389   330\n",
      "   892   947  1863   106    53    12     1   405     5   137    68   320\n",
      "    89     5  2346   163     1   920  2321   550   458  2155    83    40\n",
      "    22   220   866    91   389  1228   895    34   317     1   137 12746\n",
      "   188  2149  4302   546   290     1   291   195  1168   486     3   182\n",
      "  4852    21  1456   546  3791  5733   861  3643   546    59     1     7\n",
      "  3655  1642     6  1715   692   575  2086  1642    85  1832  1642  8384\n",
      "   314  3638  1268     5  1339   538  1111     1   692   575  2567  1715\n",
      "   575  2567   351    53    36     6     1  1284   334  1061    24    30\n",
      "    16   692   575  2764    91   389   251 10766    24  2472   723    36\n",
      "    73    64   550   602   227  1456   376   128  2764    93     6  1139\n",
      "     5  2989  1801    27  3065   259     1    57   206   765   359    57\n",
      "  4427    12   206   508   268     5     1    17   206  1513   548   206\n",
      "     6     1  2595   165    28   206     6    83    41    70   310     4\n",
      "    82    43  2321   550    36   228    64   227    96     5   605   206\n",
      "  1061  2567  1061    24   491  3076    73    43   114 10858   689    56\n",
      "    36   270   370    13    10     1     3    61    77   170 19262    15\n",
      " 13236   922   235    16    44  5856 17081  5200     9 11059   749 31315\n",
      "   235   318    93     9     6   142    44     1  1715   575]\n"
     ]
    }
   ],
   "source": [
    "max_review_length = 250\n",
    "X_train = pad_sequences(train['total_txt'], maxlen=max_review_length)  #padding zeros at the begining of each review to make max len as 200\n",
    "X_test = pad_sequences(test['total_txt'], maxlen=max_review_length)\n",
    "X_cv = pad_sequences(cv['total_txt'], maxlen=max_review_length)\n",
    "print(X_train.shape)\n",
    "print(X_train[256])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q5u8A-oqFnLz"
   },
   "source": [
    "**Tokenizing School State**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "YAH7SubWFcvn",
    "outputId": "c9d2b494-8c20-4ac7-e33b-d80d0c5957bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32775, 1)\n",
      "[2]\n"
     ]
    }
   ],
   "source": [
    "max_review_length = 1\n",
    "X_train_school_state = pad_sequences(train['school_state'], maxlen=max_review_length)  \n",
    "X_test_school_state = pad_sequences(test['school_state'], maxlen=max_review_length)\n",
    "X_cv_school_state = pad_sequences(cv['school_state'], maxlen=max_review_length)\n",
    "print(X_test_school_state.shape)\n",
    "print(X_test_school_state[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IuAQROitGDiZ"
   },
   "source": [
    "**Tokenizing the project_grade_category**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "E6tI6-tJGHg5",
    "outputId": "59b44c7a-5bad-412a-e142-c85ca7e95a42"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(61178, 1)\n",
      "[2]\n"
     ]
    }
   ],
   "source": [
    "max_review_length = 1\n",
    "X_train_project_grade = pad_sequences(train['project_grade_category'], maxlen=max_review_length)\n",
    "X_test_project_grade = pad_sequences(test['project_grade_category'], maxlen=max_review_length)\n",
    "X_cv_project_grade = pad_sequences(cv['project_grade_category'], maxlen=max_review_length)\n",
    "print(X_train_project_grade.shape)\n",
    "print(X_train_project_grade[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SqJGmRAdGOg0"
   },
   "source": [
    "**Tokenizing the project categories**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "6FvKWp2AGN7C",
    "outputId": "192941e3-b40d-4d79-bd3e-751bcf43db9a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(61178, 1)\n",
      "[36]\n"
     ]
    }
   ],
   "source": [
    "max_review_length = 1\n",
    "X_train_project_cat = pad_sequences(train['project_subject_categories'], maxlen=max_review_length)  #padding zeros at the begining of each review to make max len as 200\n",
    "X_test_project_cat = pad_sequences(test['project_subject_categories'], maxlen=max_review_length)\n",
    "X_cv_project_cat = pad_sequences(cv['project_subject_categories'], maxlen=max_review_length)\n",
    "print(X_train_project_cat.shape)\n",
    "print(X_train_project_cat[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X9LgEe8xGkWN"
   },
   "source": [
    "**Tokenizing the project subcategories**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "SwmRDwNoGrNv",
    "outputId": "fe4ee1ac-2b96-44f8-97ab-fd6649622c2b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(61178, 1)\n",
      "[110]\n"
     ]
    }
   ],
   "source": [
    "max_review_length = 1\n",
    "X_train_project_subcat = pad_sequences(train['project_subject_subcategories'], maxlen=max_review_length)  \n",
    "X_test_project_subcat = pad_sequences(test['project_subject_subcategories'], maxlen=max_review_length)\n",
    "X_cv_project_subcat = pad_sequences(cv['project_subject_subcategories'], maxlen=max_review_length)\n",
    "print(X_train_project_subcat.shape)\n",
    "print(X_train_project_subcat[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NSSvuneQG6_z"
   },
   "source": [
    "**Tokenizing the teacher prefix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "tFWR05hTG2qo",
    "outputId": "7acebcf6-98bb-4885-aa91-80fc37278fb1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(61178, 1)\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "max_review_length = 1\n",
    "X_train_teacher_prefix = pad_sequences(train['teacher_prefix'], maxlen=max_review_length)  #padding zeros at the begining of each review to make max len as 200\n",
    "X_test_teacher_prefix = pad_sequences(test['teacher_prefix'], maxlen=max_review_length)\n",
    "X_cv_teacher_prefix = pad_sequences(cv['teacher_prefix'], maxlen=max_review_length)\n",
    "print(X_train_teacher_prefix.shape)\n",
    "print(X_test_teacher_prefix[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 584
    },
    "colab_type": "code",
    "id": "GDbfAgM9HD-Z",
    "outputId": "d41a1299-5116-455a-9eec-cddd2d7064ad"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>teacher_prefix</th>\n",
       "      <th>school_state</th>\n",
       "      <th>project_grade_category</th>\n",
       "      <th>project_subject_categories</th>\n",
       "      <th>project_subject_subcategories</th>\n",
       "      <th>total_txt</th>\n",
       "      <th>remaining_input</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21875</th>\n",
       "      <td>[3]</td>\n",
       "      <td>[26]</td>\n",
       "      <td>[2]</td>\n",
       "      <td>[36]</td>\n",
       "      <td>[110]</td>\n",
       "      <td>[4265, 54, 167, 78, 94, 144, 2, 7921, 20774, 1...</td>\n",
       "      <td>74.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53730</th>\n",
       "      <td>[2]</td>\n",
       "      <td>[27]</td>\n",
       "      <td>[2]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[1378, 18, 392, 2219, 1, 3, 3, 37, 31, 4435, 3...</td>\n",
       "      <td>94.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12461</th>\n",
       "      <td>[2]</td>\n",
       "      <td>[6]</td>\n",
       "      <td>[3]</td>\n",
       "      <td>[2]</td>\n",
       "      <td>[26]</td>\n",
       "      <td>[142, 7621, 3058, 4167, 1, 19, 161, 75, 4, 62,...</td>\n",
       "      <td>124.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31005</th>\n",
       "      <td>[1]</td>\n",
       "      <td>[19]</td>\n",
       "      <td>[3]</td>\n",
       "      <td>[31]</td>\n",
       "      <td>[74]</td>\n",
       "      <td>[725, 33, 162, 2, 382, 127, 1614, 541, 1032, 3...</td>\n",
       "      <td>141.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6248</th>\n",
       "      <td>[2]</td>\n",
       "      <td>[11]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[4885, 11, 14, 1, 106, 53, 1, 393, 350, 49, 40...</td>\n",
       "      <td>607.99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      teacher_prefix  ... remaining_input\n",
       "21875            [3]  ...           74.49\n",
       "53730            [2]  ...           94.48\n",
       "12461            [2]  ...          124.49\n",
       "31005            [1]  ...          141.51\n",
       "6248             [2]  ...          607.99\n",
       "\n",
       "[5 rows x 7 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "R38W6MB4HLt9"
   },
   "source": [
    "# **Model 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b3-2dXx-HIlU"
   },
   "outputs": [],
   "source": [
    "#AUC score\n",
    "def auc( y_true, y_pred ) :\n",
    "    score = tf.py_func( lambda y_true, y_pred : roc_auc_score( y_true, y_pred, average='macro', sample_weight=None).astype('float32'),\n",
    "                        [y_true, y_pred],\n",
    "                        'float32',\n",
    "                        stateful=True,\n",
    "                        name='sklearnAUC' )\n",
    "    return score\n",
    "\n",
    "\n",
    "def step_decay(epoch):\n",
    "    initial_lrate = 0.0001\n",
    "    drop = 1e-6\n",
    "    epochs_drop = 1\n",
    "    lrate = initial_lrate * math.pow(drop, math.floor((1+epoch)/epochs_drop))\n",
    "    return lrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "8COLmngMIA6a",
    "outputId": "316b4ac7-b678-435f-e588-7d3797fa8669"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0818 07:55:42.802108 139944755865472 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0818 07:55:44.864600 139944755865472 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0818 07:55:44.888937 139944755865472 deprecation.py:323] From <ipython-input-65-c99e1f58a26a>:6: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, there are two\n",
      "    options available in V2.\n",
      "    - tf.py_function takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
      "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
      "    stateful argument making all functions stateful.\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 250)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 250, 300)     17061300    input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_1 (SpatialDro (None, 250, 300)     0           embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_5 (InputLayer)            (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_6 (InputLayer)            (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_7 (InputLayer)            (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "cu_dnnlstm_1 (CuDNNLSTM)        (None, 250, 128)     220160      spatial_dropout1d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, 1, 2)         104         input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_4 (Embedding)         (None, 1, 2)         10          input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_5 (Embedding)         (None, 1, 2)         100         input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_6 (Embedding)         (None, 1, 50)        19250       input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_7 (Embedding)         (None, 1, 5)         30          input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_8 (InputLayer)            (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 32000)        0           cu_dnnlstm_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 2)            0           embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 2)            0           embedding_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 2)            0           embedding_5[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)             (None, 50)           0           embedding_6[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_6 (Flatten)             (None, 5)            0           embedding_7[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 16)           32          input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 32077)        0           flatten_1[0][0]                  \n",
      "                                                                 flatten_2[0][0]                  \n",
      "                                                                 flatten_3[0][0]                  \n",
      "                                                                 flatten_4[0][0]                  \n",
      "                                                                 flatten_5[0][0]                  \n",
      "                                                                 flatten_6[0][0]                  \n",
      "                                                                 dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 128)          4105984     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 128)          0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 64)           8256        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 64)           0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 64)           256         dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 32)           2080        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 32)           0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 2)            66          dropout_3[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 21,417,628\n",
      "Trainable params: 4,356,200\n",
      "Non-trainable params: 17,061,428\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#input 1\n",
    "input1 = Input(shape=(250,))\n",
    "x1 = Embedding(input_dim=56871,output_dim= 300,weights=[embedding_mat(feature_names[5])],trainable=False)(input1)\n",
    "x1 = SpatialDropout1D(0.3)(x1)\n",
    "x1 = CuDNNLSTM(128,return_sequences=True)(x1)\n",
    "x1 = Flatten()(x1)\n",
    "\n",
    "#input 2\n",
    "input2 = Input(shape=(1,))\n",
    "x2 = Embedding(input_dim= 52,output_dim= 2)(input2)\n",
    "#x2 = SpatialDropout1D(0.3)(x2)\n",
    "x2 = Flatten()(x2)\n",
    "\n",
    "#input 3\n",
    "input3 = Input(shape=(1,))\n",
    "x3 = Embedding(input_dim= 5,output_dim= 2)(input3)\n",
    "#x3 = SpatialDropout1D(0.3)(x3)\n",
    "x3 = Flatten()(x3)\n",
    "\n",
    "#input 4\n",
    "input4 = Input(shape=(1,))\n",
    "x4 = Embedding(input_dim=50,output_dim= 2)(input4)\n",
    "#x4 = SpatialDropout1D(0.3)(x4)\n",
    "x4 = Flatten()(x4)\n",
    "\n",
    "#input 5\n",
    "input5 = Input(shape=(1,))\n",
    "x5 = Embedding(input_dim= 385,output_dim= 50)(input5)\n",
    "#x5 = SpatialDropout1D(0.3)(x5)\n",
    "x5 = Flatten()(x5)\n",
    "\n",
    "#input 6\n",
    "input6 = Input(shape=(1,))\n",
    "x6 = Embedding(input_dim= 6,output_dim= 5)(input6)\n",
    "#x6 = SpatialDropout1D(0.3)(x6)\n",
    "x6 = Flatten()(x6)\n",
    "#input 7\n",
    "input7 = Input(shape=(1,))\n",
    "x7 = Dense(16,activation='relu',kernel_initializer=he_normal(),kernel_regularizer=l2(0.0001))(input7)\n",
    "#x7 = Flatten()(x7)\n",
    "#merging all the inputs \n",
    "concat = concatenate([x1,x2,x3,x4,x5,x6,x7])\n",
    "#x = BatchNormalization()(concat)\n",
    "\n",
    "x = Dense(128,activation='relu',kernel_initializer=he_normal(),kernel_regularizer=l2(0.0001))(concat)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(64,activation='relu',kernel_initializer=he_normal(),kernel_regularizer=l2(0.0001))(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dense(32,activation='relu',kernel_initializer=he_normal(),kernel_regularizer=l2(0.0001))(x)\n",
    "x = Dropout(0.5)(x)\n",
    "output = Dense(2, activation = 'softmax')(x)\n",
    " \n",
    "# create model with seven inputs\n",
    "model = Model([input1,input2,input3,input4,input5,input6,input7], output)\n",
    "tensorboard = TensorBoard(log_dir='logs/{}'.format(time()))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.Adam(lr=0.0006,decay = 1e-4),metrics=[auc])\n",
    "#lrate = LearningRateScheduler(step_decay)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "4f3vXCBlM37n",
    "outputId": "33dbfb09-db50-4960-a6b8-f6659bd684a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 61178 samples, validate on 15295 samples\n",
      "Epoch 1/20\n",
      "61178/61178 [==============================] - 14s 229us/step - loss: 0.4548 - auc: 0.5462 - val_loss: 0.4585 - val_auc: 0.5815\n",
      "\n",
      "Epoch 00001: val_auc improved from -inf to 0.58154, saving model to weights_copy.best.hdf5\n",
      "Epoch 2/20\n",
      "61178/61178 [==============================] - 14s 229us/step - loss: 0.4525 - auc: 0.5508 - val_loss: 0.4460 - val_auc: 0.5995\n",
      "\n",
      "Epoch 00002: val_auc improved from 0.58154 to 0.59953, saving model to weights_copy.best.hdf5\n",
      "Epoch 3/20\n",
      "61178/61178 [==============================] - 14s 231us/step - loss: 0.4450 - auc: 0.5654 - val_loss: 0.4341 - val_auc: 0.6428\n",
      "\n",
      "Epoch 00003: val_auc improved from 0.59953 to 0.64283, saving model to weights_copy.best.hdf5\n",
      "Epoch 4/20\n",
      "61178/61178 [==============================] - 14s 232us/step - loss: 0.4318 - auc: 0.6218 - val_loss: 0.4227 - val_auc: 0.6967\n",
      "\n",
      "Epoch 00004: val_auc improved from 0.64283 to 0.69671, saving model to weights_copy.best.hdf5\n",
      "Epoch 5/20\n",
      "61178/61178 [==============================] - 14s 233us/step - loss: 0.4185 - auc: 0.6677 - val_loss: 0.4058 - val_auc: 0.7153\n",
      "\n",
      "Epoch 00005: val_auc improved from 0.69671 to 0.71531, saving model to weights_copy.best.hdf5\n",
      "Epoch 6/20\n",
      "61178/61178 [==============================] - 14s 232us/step - loss: 0.4114 - auc: 0.6864 - val_loss: 0.4028 - val_auc: 0.7265\n",
      "\n",
      "Epoch 00006: val_auc improved from 0.71531 to 0.72651, saving model to weights_copy.best.hdf5\n",
      "Epoch 7/20\n",
      "61178/61178 [==============================] - 14s 232us/step - loss: 0.4075 - auc: 0.6942 - val_loss: 0.3970 - val_auc: 0.7359\n",
      "\n",
      "Epoch 00007: val_auc improved from 0.72651 to 0.73586, saving model to weights_copy.best.hdf5\n",
      "Epoch 8/20\n",
      "61178/61178 [==============================] - 14s 231us/step - loss: 0.4028 - auc: 0.7030 - val_loss: 0.3917 - val_auc: 0.7354\n",
      "\n",
      "Epoch 00008: val_auc did not improve from 0.73586\n",
      "Epoch 9/20\n",
      "61178/61178 [==============================] - 14s 231us/step - loss: 0.4012 - auc: 0.7021 - val_loss: 0.3895 - val_auc: 0.7373\n",
      "\n",
      "Epoch 00009: val_auc improved from 0.73586 to 0.73727, saving model to weights_copy.best.hdf5\n",
      "Epoch 10/20\n",
      "61178/61178 [==============================] - 14s 232us/step - loss: 0.3972 - auc: 0.7124 - val_loss: 0.3872 - val_auc: 0.7295\n",
      "\n",
      "Epoch 00010: val_auc did not improve from 0.73727\n",
      "Epoch 11/20\n",
      "61178/61178 [==============================] - 14s 232us/step - loss: 0.3952 - auc: 0.7177 - val_loss: 0.3868 - val_auc: 0.7518\n",
      "\n",
      "Epoch 00011: val_auc improved from 0.73727 to 0.75181, saving model to weights_copy.best.hdf5\n",
      "Epoch 12/20\n",
      "61178/61178 [==============================] - 14s 231us/step - loss: 0.3925 - auc: 0.7226 - val_loss: 0.3836 - val_auc: 0.7531\n",
      "\n",
      "Epoch 00012: val_auc improved from 0.75181 to 0.75309, saving model to weights_copy.best.hdf5\n",
      "Epoch 13/20\n",
      "61178/61178 [==============================] - 14s 232us/step - loss: 0.3908 - auc: 0.7250 - val_loss: 0.3825 - val_auc: 0.7565\n",
      "\n",
      "Epoch 00013: val_auc improved from 0.75309 to 0.75645, saving model to weights_copy.best.hdf5\n",
      "Epoch 14/20\n",
      "61178/61178 [==============================] - 14s 232us/step - loss: 0.3878 - auc: 0.7305 - val_loss: 0.3831 - val_auc: 0.7576\n",
      "\n",
      "Epoch 00014: val_auc improved from 0.75645 to 0.75763, saving model to weights_copy.best.hdf5\n",
      "Epoch 15/20\n",
      "61178/61178 [==============================] - 14s 232us/step - loss: 0.3853 - auc: 0.7355 - val_loss: 0.3782 - val_auc: 0.7543\n",
      "\n",
      "Epoch 00015: val_auc did not improve from 0.75763\n",
      "Epoch 16/20\n",
      "61178/61178 [==============================] - 14s 232us/step - loss: 0.3833 - auc: 0.7389 - val_loss: 0.3782 - val_auc: 0.7569\n",
      "\n",
      "Epoch 00016: val_auc did not improve from 0.75763\n",
      "Epoch 17/20\n",
      "61178/61178 [==============================] - 14s 232us/step - loss: 0.3799 - auc: 0.7478 - val_loss: 0.3744 - val_auc: 0.7596\n",
      "\n",
      "Epoch 00017: val_auc improved from 0.75763 to 0.75957, saving model to weights_copy.best.hdf5\n",
      "Epoch 18/20\n",
      "61178/61178 [==============================] - 14s 231us/step - loss: 0.3787 - auc: 0.7490 - val_loss: 0.3770 - val_auc: 0.7563\n",
      "\n",
      "Epoch 00018: val_auc did not improve from 0.75957\n",
      "Epoch 19/20\n",
      "61178/61178 [==============================] - 14s 232us/step - loss: 0.3762 - auc: 0.7545 - val_loss: 0.3738 - val_auc: 0.7625\n",
      "\n",
      "Epoch 00019: val_auc improved from 0.75957 to 0.76247, saving model to weights_copy.best.hdf5\n",
      "Epoch 20/20\n",
      "61178/61178 [==============================] - 14s 232us/step - loss: 0.3738 - auc: 0.7578 - val_loss: 0.3800 - val_auc: 0.7545\n",
      "\n",
      "Epoch 00020: val_auc did not improve from 0.76247\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f45d9e682b0>"
      ]
     },
     "execution_count": 72,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model fitting\n",
    "#https://machinelearningmastery.com/check-point-deep-learning-models-keras/\n",
    "filepath=\"weights_copy.best.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_auc', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint,tensorboard]\n",
    "model.fit([X_train,X_train_school_state,X_train_project_grade,X_train_project_cat,X_train_project_subcat,\n",
    "           X_train_teacher_prefix,train['remaining_input']], y_train, nb_epoch=20,verbose=1,batch_size=256,\n",
    "          validation_data=([X_cv,X_cv_school_state,X_cv_project_grade,X_cv_project_cat,X_cv_project_subcat,\n",
    "           X_cv_teacher_prefix,cv['remaining_input']]  , y_cv),callbacks =callbacks_list,class_weight = class_wght )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1iWYV7V41yOk"
   },
   "outputs": [],
   "source": [
    "#input 1\n",
    "input1 = Input(shape=(250,))\n",
    "x1 = Embedding(input_dim=56871,output_dim= 300,weights=[embedding_mat(feature_names[5])],trainable=False)(input1)\n",
    "x1 = SpatialDropout1D(0.3)(x1)\n",
    "x1 = CuDNNLSTM(128,return_sequences=True)(x1)\n",
    "x1 = Flatten()(x1)\n",
    "\n",
    "#input 2\n",
    "input2 = Input(shape=(1,))\n",
    "x2 = Embedding(input_dim= 52,output_dim= 2)(input2)\n",
    "#x2 = SpatialDropout1D(0.3)(x2)\n",
    "x2 = Flatten()(x2)\n",
    "\n",
    "#input 3\n",
    "input3 = Input(shape=(1,))\n",
    "x3 = Embedding(input_dim= 5,output_dim= 2)(input3)\n",
    "#x3 = SpatialDropout1D(0.3)(x3)\n",
    "x3 = Flatten()(x3)\n",
    "\n",
    "#input 4\n",
    "input4 = Input(shape=(1,))\n",
    "x4 = Embedding(input_dim=50,output_dim= 2)(input4)\n",
    "#x4 = SpatialDropout1D(0.3)(x4)\n",
    "x4 = Flatten()(x4)\n",
    "\n",
    "#input 5\n",
    "input5 = Input(shape=(1,))\n",
    "x5 = Embedding(input_dim= 385,output_dim= 50)(input5)\n",
    "#x5 = SpatialDropout1D(0.3)(x5)\n",
    "x5 = Flatten()(x5)\n",
    "\n",
    "#input 6\n",
    "input6 = Input(shape=(1,))\n",
    "x6 = Embedding(input_dim= 6,output_dim= 5)(input6)\n",
    "#x6 = SpatialDropout1D(0.3)(x6)\n",
    "x6 = Flatten()(x6)\n",
    "\n",
    "#input 7\n",
    "input7 = Input(shape=(1,))\n",
    "x7 = Dense(16,activation='relu',kernel_initializer=he_normal(),kernel_regularizer=l2(0.0001))(input7)\n",
    "#x7 = Flatten()(x7)\n",
    "#merging all the inputs \n",
    "concat = concatenate([x1,x2,x3,x4,x5,x6,x7])\n",
    "#x = BatchNormalization()(concat)\n",
    "\n",
    "x = Dense(128,activation='relu',kernel_initializer=he_normal(),kernel_regularizer=l2(0.0001))(concat)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(64,activation='relu',kernel_initializer=he_normal(),kernel_regularizer=l2(0.0001))(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dense(32,activation='relu',kernel_initializer=he_normal(),kernel_regularizer=l2(0.0001))(x)\n",
    "x = Dropout(0.5)(x)\n",
    "output = Dense(2, activation = 'softmax')(x)\n",
    " \n",
    "# create model with seven inputs\n",
    "model = Model([input1,input2,input3,input4,input5,input6,input7], output)\n",
    "tensorboard = TensorBoard(log_dir='logs/{}'.format(time()))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.Adam(lr=0.0006,decay = 1e-4),metrics=[auc])\n",
    "model.load_weights(\"/content/weights_copy.best.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "id": "y4o9Zs63uYuA",
    "outputId": "41080da7-9152-42a6-d3e0-dc6706020981"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Auc for test data: 0.760\n",
      "Auc for CV data: 0.763\n",
      "Auc for train data: 0.791\n"
     ]
    }
   ],
   "source": [
    "print(\"Auc for test data: %0.3f\"%roc_auc_score(y_test,model.predict([X_test,X_test_school_state,X_test_project_grade,X_test_project_cat,X_test_project_subcat,\n",
    "           X_test_teacher_prefix,test['remaining_input']])))\n",
    "print(\"Auc for CV data: %0.3f\"%roc_auc_score(y_cv,model.predict([X_cv,X_cv_school_state,X_cv_project_grade,X_cv_project_cat,X_cv_project_subcat,\n",
    "           X_cv_teacher_prefix,cv['remaining_input']])))\n",
    "print(\"Auc for train data: %0.3f\"%roc_auc_score(y_train,model.predict([X_train,X_train_school_state,X_train_project_grade,X_train_project_cat,X_train_project_subcat,\n",
    "           X_train_teacher_prefix,train['remaining_input']])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Model 1 Train](M1_1.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Model 1 Val](M1_1_val.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mBiCxlNQvPMz"
   },
   "source": [
    "# Model 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GHMn_6rnxrZH"
   },
   "source": [
    "**Selecting the Top features based on IDF values for the Text part of the project_data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 441
    },
    "colab_type": "code",
    "id": "B_wmvXaUvSz6",
    "outputId": "b3c4c3b2-80ef-4896-b550-a4bc3e7a0acd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>teacher_id</th>\n",
       "      <th>teacher_prefix</th>\n",
       "      <th>school_state</th>\n",
       "      <th>project_submitted_datetime</th>\n",
       "      <th>project_grade_category</th>\n",
       "      <th>project_subject_categories</th>\n",
       "      <th>project_subject_subcategories</th>\n",
       "      <th>project_title</th>\n",
       "      <th>project_essay_1</th>\n",
       "      <th>project_essay_2</th>\n",
       "      <th>project_essay_3</th>\n",
       "      <th>project_essay_4</th>\n",
       "      <th>project_resource_summary</th>\n",
       "      <th>teacher_number_of_previously_posted_projects</th>\n",
       "      <th>project_is_approved</th>\n",
       "      <th>presence_of_the_numerical_digits</th>\n",
       "      <th>essay</th>\n",
       "      <th>price</th>\n",
       "      <th>quantity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>p253737</td>\n",
       "      <td>c90749f5d961ff158d4b4d1e7dc665fc</td>\n",
       "      <td>mrs</td>\n",
       "      <td>in</td>\n",
       "      <td>2016-12-05 13:43:57</td>\n",
       "      <td>grades_prek_2</td>\n",
       "      <td>literacy_language</td>\n",
       "      <td>esl_literacy</td>\n",
       "      <td>educational support english learners home</td>\n",
       "      <td>My students are English learners that are work...</td>\n",
       "      <td>\\\"The limits of your language are the limits o...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>My students need opportunities to practice beg...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>students english learners working english seco...</td>\n",
       "      <td>154.60</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>p258326</td>\n",
       "      <td>897464ce9ddc600bced1151f324dd63a</td>\n",
       "      <td>mr</td>\n",
       "      <td>fl</td>\n",
       "      <td>2016-10-25 09:22:10</td>\n",
       "      <td>grades_6_8</td>\n",
       "      <td>history_civics_health_sports</td>\n",
       "      <td>civics_government_teamsports</td>\n",
       "      <td>wanted projector hungry learners</td>\n",
       "      <td>Our students arrive to our school eager to lea...</td>\n",
       "      <td>The projector we need for our school is very c...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>My students need a projector to help with view...</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>students arrive school eager learn polite gene...</td>\n",
       "      <td>299.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>p182444</td>\n",
       "      <td>3465aaf82da834c0582ebd0ef8040ca0</td>\n",
       "      <td>ms</td>\n",
       "      <td>az</td>\n",
       "      <td>2016-08-31 12:03:56</td>\n",
       "      <td>grades_6_8</td>\n",
       "      <td>health_sports</td>\n",
       "      <td>health_wellness_teamsports</td>\n",
       "      <td>soccer equipment awesome middle school students</td>\n",
       "      <td>\\r\\n\\\"True champions aren't always the ones th...</td>\n",
       "      <td>The students on the campus come to school know...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>My students need shine guards, athletic socks,...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>true champions not always ones win guts mia ha...</td>\n",
       "      <td>516.85</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0       id  ...   price quantity\n",
       "0           0  p253737  ...  154.60       23\n",
       "1           1  p258326  ...  299.00        1\n",
       "2           2  p182444  ...  516.85       22\n",
       "\n",
       "[3 rows x 21 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Reading the dataset\n",
    "project_data = pd.read_csv('processed_train_data.csv')\n",
    "project_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oikPpk2myCpa"
   },
   "outputs": [],
   "source": [
    "#combining teacher number of previously posted projects, presence of the numberical digits price and quantity into a single feature\n",
    "project_data.drop(['Unnamed: 0'], axis =1 , inplace = True)\n",
    "class_label = project_data['project_is_approved']\n",
    "project_data['remaining_input'] = project_data['teacher_number_of_previously_posted_projects']  +\\\n",
    "                                    project_data['presence_of_the_numerical_digits']  + \\\n",
    "                                    project_data['price'] + project_data['quantity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FDnRnzqbyG3A"
   },
   "outputs": [],
   "source": [
    "#train test split\n",
    "train,test,y_train,y_test = train_test_split(project_data, class_label , stratify = class_label, train_size = 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-OypqHkxyKhq"
   },
   "outputs": [],
   "source": [
    "train,cv,y_train,y_cv = train_test_split(train,y_train,stratify = y_train,train_size = 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "id": "XVM8FWF1yPft",
    "outputId": "3855ce93-4e40-4068-f7d8-651650e85114"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the Train dataset:  61178\n",
      "Shape of the Test dataset:  32775\n",
      "Shape of the CV Dataset: 15295\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of the Train dataset: \", train.shape[0])\n",
    "print(\"Shape of the Test dataset: \", test.shape[0])\n",
    "print(\"Shape of the CV Dataset:\", cv.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vS9hvHq7yTpg"
   },
   "outputs": [],
   "source": [
    "# converting the class labels to one hot encoding for keras model evaluation\n",
    "from keras.utils import to_categorical\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "y_cv = to_categorical(y_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IJbG4J-nyVF-"
   },
   "outputs": [],
   "source": [
    "# reading the pre trained word vectors file\n",
    "dbfile = open('/content/glove_vectors', 'rb')      \n",
    "db = pickle.load(dbfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ze6VR74jye74"
   },
   "outputs": [],
   "source": [
    "#creating a matrix of word as rows and columns as 50 dmin vectors of words\n",
    "def embedding_mat(word_index,embedding_dim = 300):\n",
    "    embedding_matrix = np.zeros((len(word_index) + 1, embedding_dim))\n",
    "    for word, i in word_index.items():\n",
    "        embedding_vector =db.get(word)\n",
    "        if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "colab_type": "code",
    "id": "PUA0zQryyjOM",
    "outputId": "bf4b390a-604c-4e9d-cc56-d24db95f6553"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'IDF score')"
      ]
     },
     "execution_count": 88,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAD8CAYAAAB6paOMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRwgAIDlCAADJEQIASI4QAEBy/wePpeWRUICGPQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#tfidf vectorization of text data\n",
    "tfidf = TfidfVectorizer()\n",
    "data_text = tfidf.fit_transform(train['essay'])\n",
    "plt.boxplot(tfidf.idf_)\n",
    "plt.ylabel(\"IDF score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "DrzrarQyynZe",
    "outputId": "a8070341-7418-4a6b-cd69-698e4d949d1d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 25 percentile of idf score is : [9.31350907]\n",
      "The 75 percentile of idf score is : [11.32841209]\n"
     ]
    }
   ],
   "source": [
    "print(\"The 25 percentile of idf score is :\", np.percentile(tfidf.idf_,[25]))\n",
    "print(\"The 75 percentile of idf score is :\",np.percentile(tfidf.idf_,[75]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KHWTw0jmys9g"
   },
   "outputs": [],
   "source": [
    "feature_idf = zip(tfidf.get_feature_names(),tfidf.idf_)\n",
    "\n",
    "feature_name = []\n",
    "for x,y in feature_idf:\n",
    "    \n",
    "    if y >=9.31350907 and 11.32841209 :\n",
    "        feature_name.append(x)\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s4QBZ5oiywbh"
   },
   "outputs": [],
   "source": [
    "#Selecting only those words which have idf values between 25th percentile to 75th percentile\n",
    "def few_text(df):\n",
    "    processed_text = []\n",
    "    for text in df:\n",
    "        sent = \" \"\n",
    "        words = text.split()\n",
    "        for word in words:\n",
    "            if word in feature_name:\n",
    "                sent = ' ' + word\n",
    "            else:\n",
    "                pass\n",
    "        processed_text.append(sent)\n",
    "    return processed_text\n",
    "\n",
    "train['processed_essay'] = few_text(train['essay'])\n",
    "test['processed_essay'] = few_text(test['essay'])\n",
    "cv['processed_essay'] = few_text(cv['essay'])\n",
    "\n",
    "train.to_csv(\"model-train.csv\")\n",
    "test.to_csv(\"model-test.csv\")\n",
    "cv.to_csv(\"model-cv.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Alri96MPy2-e"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"model-train.csv\")\n",
    "test = pd.read_csv(\"model-test.csv\")\n",
    "cv = pd.read_csv(\"model-cv.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M5csXAtQy5U9"
   },
   "outputs": [],
   "source": [
    "train['total_txt'] = train['project_title'] + ' ' + train['essay'] + ' ' + train['project_resource_summary']\n",
    "test['total_txt'] = test['project_title'] + ' ' + test['essay'] + ' ' + test['project_resource_summary']\n",
    "cv['total_txt'] = cv['project_title'] + ' ' + cv['essay'] + ' ' + cv['project_resource_summary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U4qp4_wvy8Lm"
   },
   "outputs": [],
   "source": [
    "y_train = train['project_is_approved']\n",
    "y_test = test['project_is_approved']\n",
    "y_cv = cv['project_is_approved']\n",
    "\n",
    "# converting the class labels to one hot encoding for keras model evaluation\n",
    "from keras.utils import to_categorical\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "y_cv = to_categorical(y_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_gBiWlhty-j5"
   },
   "outputs": [],
   "source": [
    "def word_ranking(train,test,cv):\n",
    "    col_names = train.columns\n",
    "    features = []\n",
    "    #performing train test split\n",
    "    \n",
    "    for col in col_names[:6]:\n",
    "        print(col)\n",
    "        bag_of_words = TfidfVectorizer(lowercase= False)\n",
    "        bow_words = bag_of_words.fit_transform(train[col])\n",
    "        print(bow_words.shape)\n",
    "        \n",
    "        #Lets now store the document term matrix in a dictionary.\n",
    "        freqs = bow_words.sum(axis=0).A1\n",
    "        index = freqs.argsort()\n",
    "        words = bag_of_words.get_feature_names()\n",
    "        \n",
    "        \n",
    "\n",
    "        # Assigning Rank to each word based on its freq of occurance. Word with highest freq is assigned rank 1 \n",
    "        word_rank = dict()\n",
    "        rank = 1\n",
    "        for i in index[::-1]:\n",
    "            k = words[i]\n",
    "            word_rank[k] = rank\n",
    "            rank+=1\n",
    "        features.append(word_rank)\n",
    "\n",
    "        #Every word in each review is replaced by its rank\n",
    "        rank = [] # list of all the review with words replaced with rank\n",
    "        for sent in train[col].values:\n",
    "            txt_row = []\n",
    "            for word in sent.split():\n",
    "                if word in word_rank.keys():\n",
    "                    txt_row.append(word_rank[word])\n",
    "                else:\n",
    "                    pass\n",
    "            rank.append(txt_row)\n",
    "        \n",
    "        train[col] = rank\n",
    "        \n",
    "        rank = [] # list of all the review with words replaced with rank\n",
    "        for sent in test[col].values:\n",
    "            txt_row = []\n",
    "            for word in sent.split():\n",
    "                if word in word_rank.keys():\n",
    "                    txt_row.append(word_rank[word])\n",
    "                else:\n",
    "                    pass\n",
    "            rank.append(txt_row)\n",
    "        \n",
    "        test[col] = rank\n",
    "        \n",
    "        rank = [] # list of all the review with words replaced with rank\n",
    "        for sent in cv[col].values:\n",
    "            txt_row = []\n",
    "            for word in sent.split():\n",
    "                if word in word_rank.keys():\n",
    "                    txt_row.append(word_rank[word])\n",
    "                else:\n",
    "                    pass\n",
    "            rank.append(txt_row)\n",
    "        \n",
    "        cv[col] = rank\n",
    "    return train,test,cv,features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H8linUt9zHx5"
   },
   "outputs": [],
   "source": [
    "col = ['id','teacher_id','project_submitted_datetime','project_title','project_essay_1', 'project_essay_2',\n",
    "       'project_essay_3', 'project_essay_4','project_resource_summary',\n",
    "       'teacher_number_of_previously_posted_projects', 'project_is_approved','price', 'quantity',\n",
    "        'presence_of_the_numerical_digits','essay']\n",
    "\n",
    "train.drop(labels=col,axis =1, inplace=True)\n",
    "test.drop(labels=col,axis =1, inplace=True)\n",
    "cv.drop(labels=col,axis =1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H3CDR32mzLrE"
   },
   "outputs": [],
   "source": [
    "col = train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EUpXkSEKzQC4"
   },
   "outputs": [],
   "source": [
    "col = ['teacher_prefix', 'school_state', 'project_grade_category',\n",
    "       'project_subject_categories', 'project_subject_subcategories','total_txt',\n",
    "       'remaining_input']\n",
    "train = train[col]\n",
    "test = test[col]\n",
    "test = test[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mV6YMiH9zQ6W"
   },
   "outputs": [],
   "source": [
    "train.replace(to_replace=np.NaN, value= str('nan'),inplace=True)\n",
    "test.replace(to_replace=np.NaN, value= str('nan'),inplace=True)\n",
    "cv.replace(to_replace=np.NaN, value= str('nan'),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 217
    },
    "colab_type": "code",
    "id": "8MHMtjZtzVqA",
    "outputId": "31bbee2d-ff53-4fb0-c2f9-4aad347a14ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "teacher_prefix\n",
      "(61178, 5)\n",
      "school_state\n",
      "(61178, 51)\n",
      "project_grade_category\n",
      "(61178, 4)\n",
      "project_subject_categories\n",
      "(61178, 50)\n",
      "project_subject_subcategories\n",
      "(61178, 384)\n",
      "total_txt\n",
      "(61178, 56980)\n"
     ]
    }
   ],
   "source": [
    "train,test,cv,feature_names =  word_ranking(train,test,cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g3KU409azWy4"
   },
   "source": [
    "Tokenizing the Text part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 385
    },
    "colab_type": "code",
    "id": "rOJCCPBQzbM2",
    "outputId": "c89f99ce-6b3f-41ba-c4cb-a15ea1d4a876"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(61178, 250)\n",
      "[    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0    12    54   669     5    45  2081\n",
      "   133     1    44    53     2   186  5894    26  1649   154   292  3031\n",
      "  1337     2   296  3860    45    42   749   292  1915  1912  1380   111\n",
      "     2    75     1    23    11    49   151    34  7364   195   531     4\n",
      "  3031     2   114   490  2190   321  2600     4     4  1352   305     2\n",
      "    30  1814   136    64   425   386   502  1657  1256   130    30   359\n",
      "   183   350    97   719  7453  1019   994    43  4595    20    38  2242\n",
      "    25    50   195  2081   133     1   168    23    20     6     1   202\n",
      "    24  1467  1103   725   386    94   559     2    28     6    83   157\n",
      "   230  2629     5   204    38 20075   162    28    42   202   160   532\n",
      "    24     7  2990  7839  2525   108    13    10     1     3   622    20\n",
      "     9   537   230   160    15   532   601    70    46   502  1657  1145\n",
      "    24   237    97    65   725    77   809  1147   386    15]\n"
     ]
    }
   ],
   "source": [
    "max_review_length = 250\n",
    "X_train = pad_sequences(train['total_txt'], maxlen=max_review_length)  #padding zeros at the begining of each review to make max len as 200\n",
    "X_test = pad_sequences(test['total_txt'], maxlen=max_review_length)\n",
    "X_cv = pad_sequences(cv['total_txt'], maxlen=max_review_length)\n",
    "print(X_train.shape)\n",
    "print(X_train[256])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4qV_3MDPzhZR"
   },
   "source": [
    "Tokenizing the school state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "oX0QuTlyziHi",
    "outputId": "743ed7e0-9837-4ffc-f7ce-2631b52bc5f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32775, 1)\n",
      "[21]\n"
     ]
    }
   ],
   "source": [
    "max_review_length = 1\n",
    "X_train_school_state = pad_sequences(train['school_state'], maxlen=max_review_length)  #padding zeros at the begining of each review to make max len as 200\n",
    "X_test_school_state = pad_sequences(test['school_state'], maxlen=max_review_length)\n",
    "X_cv_school_state = pad_sequences(cv['school_state'], maxlen=max_review_length)\n",
    "print(X_test_school_state.shape)\n",
    "print(X_test_school_state[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pt_GqxbuznB8"
   },
   "source": [
    "Tokenizing the project_grade_category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "TgdIk-XqzknD",
    "outputId": "416c4d53-83f7-4154-ea59-4ae0b0b825b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(61178, 1)\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "max_review_length = 1\n",
    "X_train_project_grade = pad_sequences(train['project_grade_category'], maxlen=max_review_length)  #padding zeros at the begining of each review to make max len as 200\n",
    "X_test_project_grade = pad_sequences(test['project_grade_category'], maxlen=max_review_length)\n",
    "X_cv_project_grade = pad_sequences(cv['project_grade_category'], maxlen=max_review_length)\n",
    "print(X_train_project_grade.shape)\n",
    "print(X_train_project_grade[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lmgDZbAYzrVV"
   },
   "source": [
    "Tokenizing the project categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "ph7NrATIzvaK",
    "outputId": "9f3676c4-aae6-4c8f-d3a9-0e18ed46442c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(61178, 1)\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "max_review_length = 1\n",
    "X_train_project_cat = pad_sequences(train['project_subject_categories'], maxlen=max_review_length)  #padding zeros at the begining of each review to make max len as 200\n",
    "X_test_project_cat = pad_sequences(test['project_subject_categories'], maxlen=max_review_length)\n",
    "X_cv_project_cat = pad_sequences(cv['project_subject_categories'], maxlen=max_review_length)\n",
    "print(X_train_project_cat.shape)\n",
    "print(X_train_project_cat[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XJ9JBhYjzyv-"
   },
   "source": [
    "Tokenizing the project subcategories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "IWuVerDfz16I",
    "outputId": "55de25f9-e5dc-4cf0-9b27-6110a214135f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(61178, 1)\n",
      "[55]\n"
     ]
    }
   ],
   "source": [
    "max_review_length = 1\n",
    "X_train_project_subcat = pad_sequences(train['project_subject_subcategories'], maxlen=max_review_length)  #padding zeros at the begining of each review to make max len as 200\n",
    "X_test_project_subcat = pad_sequences(test['project_subject_subcategories'], maxlen=max_review_length)\n",
    "X_cv_project_subcat = pad_sequences(cv['project_subject_subcategories'], maxlen=max_review_length)\n",
    "print(X_train_project_subcat.shape)\n",
    "print(X_train_project_subcat[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "-k_dsaGlz35f",
    "outputId": "edd4e2ad-89ad-421d-a052-3b679a12424c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(61178, 1)\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "max_review_length = 1\n",
    "X_train_teacher_prefix = pad_sequences(train['teacher_prefix'], maxlen=max_review_length)  #padding zeros at the begining of each review to make max len as 200\n",
    "X_test_teacher_prefix = pad_sequences(test['teacher_prefix'], maxlen=max_review_length)\n",
    "X_cv_teacher_prefix = pad_sequences(cv['teacher_prefix'], maxlen=max_review_length)\n",
    "print(X_train_teacher_prefix.shape)\n",
    "print(X_test_teacher_prefix[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 601
    },
    "colab_type": "code",
    "id": "_kvdezTyz76l",
    "outputId": "9c0ea9c4-5c3e-46ec-da9e-c02524539c77"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>teacher_prefix</th>\n",
       "      <th>school_state</th>\n",
       "      <th>project_grade_category</th>\n",
       "      <th>project_subject_categories</th>\n",
       "      <th>project_subject_subcategories</th>\n",
       "      <th>total_txt</th>\n",
       "      <th>remaining_input</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[1]</td>\n",
       "      <td>[20]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[55]</td>\n",
       "      <td>[225, 5052, 17738, 1535, 66, 5, 303, 21, 1726,...</td>\n",
       "      <td>177.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[1]</td>\n",
       "      <td>[20]</td>\n",
       "      <td>[3]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[32]</td>\n",
       "      <td>[2878, 627, 190, 155, 3083, 59, 1, 400, 120, 2...</td>\n",
       "      <td>289.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[1]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[4]</td>\n",
       "      <td>[14]</td>\n",
       "      <td>[34]</td>\n",
       "      <td>[1680, 3010, 101, 1901, 45, 1, 111, 151, 14, 1...</td>\n",
       "      <td>228.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[2]</td>\n",
       "      <td>[5]</td>\n",
       "      <td>[3]</td>\n",
       "      <td>[15]</td>\n",
       "      <td>[78]</td>\n",
       "      <td>[107, 72, 11, 1670, 1, 1470, 89, 278, 2, 860, ...</td>\n",
       "      <td>135.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[2]</td>\n",
       "      <td>[8]</td>\n",
       "      <td>[2]</td>\n",
       "      <td>[2]</td>\n",
       "      <td>[5]</td>\n",
       "      <td>[9258, 1204, 193, 1, 347, 361, 1677, 168, 327,...</td>\n",
       "      <td>293.15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  teacher_prefix  ... remaining_input\n",
       "0            [1]  ...          177.98\n",
       "1            [1]  ...          289.26\n",
       "2            [1]  ...          228.77\n",
       "3            [2]  ...          135.65\n",
       "4            [2]  ...          293.15\n",
       "\n",
       "[5 rows x 7 columns]"
      ]
     },
     "execution_count": 107,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "-l5GZiZWz-fC",
    "outputId": "3c61076b-6797-47c8-c711-e9383ffdcd4f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_25 (InputLayer)           (None, 250)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_22 (Embedding)        (None, 250, 300)     17094300    input_25[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_4 (SpatialDro (None, 250, 300)     0           embedding_22[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "input_26 (InputLayer)           (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_27 (InputLayer)           (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_28 (InputLayer)           (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_29 (InputLayer)           (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_30 (InputLayer)           (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "cu_dnnlstm_4 (CuDNNLSTM)        (None, 250, 128)     220160      spatial_dropout1d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "embedding_23 (Embedding)        (None, 1, 2)         104         input_26[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_24 (Embedding)        (None, 1, 2)         10          input_27[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_25 (Embedding)        (None, 1, 2)         100         input_28[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_26 (Embedding)        (None, 1, 50)        19250       input_29[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_27 (Embedding)        (None, 1, 5)         30          input_30[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_31 (InputLayer)           (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_19 (Flatten)            (None, 32000)        0           cu_dnnlstm_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_20 (Flatten)            (None, 2)            0           embedding_23[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_21 (Flatten)            (None, 2)            0           embedding_24[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_22 (Flatten)            (None, 2)            0           embedding_25[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_23 (Flatten)            (None, 50)           0           embedding_26[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_24 (Flatten)            (None, 5)            0           embedding_27[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 16)           32          input_31[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 32077)        0           flatten_19[0][0]                 \n",
      "                                                                 flatten_20[0][0]                 \n",
      "                                                                 flatten_21[0][0]                 \n",
      "                                                                 flatten_22[0][0]                 \n",
      "                                                                 flatten_23[0][0]                 \n",
      "                                                                 flatten_24[0][0]                 \n",
      "                                                                 dense_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 128)          4105984     concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 128)          0           dense_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 64)           8256        dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 64)           0           dense_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 64)           256         dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_19 (Dense)                (None, 32)           2080        batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 32)           0           dense_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_20 (Dense)                (None, 2)            66          dropout_12[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 21,450,628\n",
      "Trainable params: 4,356,200\n",
      "Non-trainable params: 17,094,428\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#input 1\n",
    "input1 = Input(shape=(250,))\n",
    "x1 = Embedding(input_dim=56981,output_dim= 300,weights=[embedding_mat(feature_names[5])],trainable=False)(input1)\n",
    "x1 = SpatialDropout1D(0.3)(x1)\n",
    "x1 = CuDNNLSTM(128,return_sequences=True)(x1)\n",
    "x1 = Flatten()(x1)\n",
    "\n",
    "#input 2\n",
    "input2 = Input(shape=(1,))\n",
    "x2 = Embedding(input_dim= 52,output_dim= 2)(input2)\n",
    "#x2 = SpatialDropout1D(0.3)(x2)\n",
    "x2 = Flatten()(x2)\n",
    "\n",
    "#input 3\n",
    "input3 = Input(shape=(1,))\n",
    "x3 = Embedding(input_dim= 5,output_dim= 2)(input3)\n",
    "#x3 = SpatialDropout1D(0.3)(x3)\n",
    "x3 = Flatten()(x3)\n",
    "\n",
    "#input 4\n",
    "input4 = Input(shape=(1,))\n",
    "x4 = Embedding(input_dim=50,output_dim= 2)(input4)\n",
    "#x4 = SpatialDropout1D(0.3)(x4)\n",
    "x4 = Flatten()(x4)\n",
    "\n",
    "#input 5\n",
    "input5 = Input(shape=(1,))\n",
    "x5 = Embedding(input_dim= 385,output_dim= 50)(input5)\n",
    "#x5 = SpatialDropout1D(0.3)(x5)\n",
    "x5 = Flatten()(x5)\n",
    "\n",
    "#input 6\n",
    "input6 = Input(shape=(1,))\n",
    "x6 = Embedding(input_dim= 6,output_dim= 5)(input6)\n",
    "#x6 = SpatialDropout1D(0.3)(x6)\n",
    "x6 = Flatten()(x6)\n",
    "\n",
    "#input 7\n",
    "input7 = Input(shape=(1,))\n",
    "x7 = Dense(16,activation='relu',kernel_initializer=he_normal(),kernel_regularizer=l2(0.0001))(input7)\n",
    "#x7 = Flatten()(x7)\n",
    "#merging all the inputs \n",
    "concat = concatenate([x1,x2,x3,x4,x5,x6,x7])\n",
    "#x = BatchNormalization()(concat)\n",
    "\n",
    "x = Dense(128,activation='relu',kernel_initializer=he_normal(),kernel_regularizer=l2(0.0001))(concat)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(64,activation='relu',kernel_initializer=he_normal(),kernel_regularizer=l2(0.0001))(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dense(32,activation='relu',kernel_initializer=he_normal(),kernel_regularizer=l2(0.0001))(x)\n",
    "x = Dropout(0.5)(x)\n",
    "output = Dense(2, activation = 'softmax')(x)\n",
    " \n",
    "# create model with seven inputs\n",
    "model = Model([input1,input2,input3,input4,input5,input6,input7], output)\n",
    "tensorboard = TensorBoard(log_dir='logs/{}'.format(time()))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.Adam(lr=0.0006,decay = 1e-4),metrics=[auc])\n",
    "#lrate = LearningRateScheduler(step_decay)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "rhT-FjyRBUXf",
    "outputId": "4acec6ea-769c-44f0-c52c-e27c711d5c42"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 61178 samples, validate on 15295 samples\n",
      "Epoch 1/50\n",
      "61178/61178 [==============================] - 14s 234us/step - loss: 0.4652 - auc: 0.5422 - val_loss: 0.4539 - val_auc: 0.6129\n",
      "\n",
      "Epoch 00001: val_auc improved from -inf to 0.61294, saving model to /content/weights_2.best.hdf5\n",
      "Epoch 2/50\n",
      "61178/61178 [==============================] - 14s 237us/step - loss: 0.4532 - auc: 0.5578 - val_loss: 0.4584 - val_auc: 0.6405\n",
      "\n",
      "Epoch 00002: val_auc improved from 0.61294 to 0.64049, saving model to /content/weights_2.best.hdf5\n",
      "Epoch 3/50\n",
      "61178/61178 [==============================] - 14s 236us/step - loss: 0.4344 - auc: 0.6280 - val_loss: 0.4158 - val_auc: 0.6971\n",
      "\n",
      "Epoch 00003: val_auc improved from 0.64049 to 0.69710, saving model to /content/weights_2.best.hdf5\n",
      "Epoch 4/50\n",
      "61178/61178 [==============================] - 14s 233us/step - loss: 0.4250 - auc: 0.6598 - val_loss: 0.4044 - val_auc: 0.7153\n",
      "\n",
      "Epoch 00004: val_auc improved from 0.69710 to 0.71529, saving model to /content/weights_2.best.hdf5\n",
      "Epoch 5/50\n",
      "61178/61178 [==============================] - 14s 231us/step - loss: 0.4173 - auc: 0.6778 - val_loss: 0.4019 - val_auc: 0.7236\n",
      "\n",
      "Epoch 00005: val_auc improved from 0.71529 to 0.72359, saving model to /content/weights_2.best.hdf5\n",
      "Epoch 6/50\n",
      "61178/61178 [==============================] - 14s 232us/step - loss: 0.4089 - auc: 0.6966 - val_loss: 0.3999 - val_auc: 0.7292\n",
      "\n",
      "Epoch 00006: val_auc improved from 0.72359 to 0.72922, saving model to /content/weights_2.best.hdf5\n",
      "Epoch 7/50\n",
      "61178/61178 [==============================] - 14s 232us/step - loss: 0.4046 - auc: 0.7051 - val_loss: 0.3979 - val_auc: 0.7324\n",
      "\n",
      "Epoch 00007: val_auc improved from 0.72922 to 0.73235, saving model to /content/weights_2.best.hdf5\n",
      "Epoch 8/50\n",
      "61178/61178 [==============================] - 14s 233us/step - loss: 0.4015 - auc: 0.7083 - val_loss: 0.3990 - val_auc: 0.7392\n",
      "\n",
      "Epoch 00008: val_auc improved from 0.73235 to 0.73924, saving model to /content/weights_2.best.hdf5\n",
      "Epoch 9/50\n",
      "61178/61178 [==============================] - 14s 233us/step - loss: 0.3983 - auc: 0.7167 - val_loss: 0.3972 - val_auc: 0.7410\n",
      "\n",
      "Epoch 00009: val_auc improved from 0.73924 to 0.74101, saving model to /content/weights_2.best.hdf5\n",
      "Epoch 10/50\n",
      "61178/61178 [==============================] - 14s 233us/step - loss: 0.3957 - auc: 0.7180 - val_loss: 0.3930 - val_auc: 0.7459\n",
      "\n",
      "Epoch 00010: val_auc improved from 0.74101 to 0.74589, saving model to /content/weights_2.best.hdf5\n",
      "Epoch 11/50\n",
      "61178/61178 [==============================] - 14s 235us/step - loss: 0.3919 - auc: 0.7279 - val_loss: 0.3933 - val_auc: 0.7478\n",
      "\n",
      "Epoch 00011: val_auc improved from 0.74589 to 0.74781, saving model to /content/weights_2.best.hdf5\n",
      "Epoch 12/50\n",
      "61178/61178 [==============================] - 14s 232us/step - loss: 0.3886 - auc: 0.7349 - val_loss: 0.3897 - val_auc: 0.7504\n",
      "\n",
      "Epoch 00012: val_auc improved from 0.74781 to 0.75038, saving model to /content/weights_2.best.hdf5\n",
      "Epoch 13/50\n",
      "61178/61178 [==============================] - 14s 233us/step - loss: 0.3863 - auc: 0.7385 - val_loss: 0.3838 - val_auc: 0.7489\n",
      "\n",
      "Epoch 00013: val_auc did not improve from 0.75038\n",
      "Epoch 14/50\n",
      "61178/61178 [==============================] - 14s 233us/step - loss: 0.3838 - auc: 0.7429 - val_loss: 0.3808 - val_auc: 0.7554\n",
      "\n",
      "Epoch 00014: val_auc improved from 0.75038 to 0.75540, saving model to /content/weights_2.best.hdf5\n",
      "Epoch 15/50\n",
      "61178/61178 [==============================] - 14s 232us/step - loss: 0.3811 - auc: 0.7460 - val_loss: 0.3796 - val_auc: 0.7547\n",
      "\n",
      "Epoch 00015: val_auc did not improve from 0.75540\n",
      "Epoch 16/50\n",
      "61178/61178 [==============================] - 14s 233us/step - loss: 0.3781 - auc: 0.7517 - val_loss: 0.3793 - val_auc: 0.7554\n",
      "\n",
      "Epoch 00016: val_auc improved from 0.75540 to 0.75545, saving model to /content/weights_2.best.hdf5\n",
      "Epoch 17/50\n",
      "61178/61178 [==============================] - 14s 233us/step - loss: 0.3755 - auc: 0.7578 - val_loss: 0.3774 - val_auc: 0.7557\n",
      "\n",
      "Epoch 00017: val_auc improved from 0.75545 to 0.75573, saving model to /content/weights_2.best.hdf5\n",
      "Epoch 18/50\n",
      "61178/61178 [==============================] - 14s 232us/step - loss: 0.3760 - auc: 0.7586 - val_loss: 0.3781 - val_auc: 0.7558\n",
      "\n",
      "Epoch 00018: val_auc improved from 0.75573 to 0.75583, saving model to /content/weights_2.best.hdf5\n",
      "Epoch 19/50\n",
      "61178/61178 [==============================] - 14s 233us/step - loss: 0.3716 - auc: 0.7647 - val_loss: 0.3759 - val_auc: 0.7587\n",
      "\n",
      "Epoch 00019: val_auc improved from 0.75583 to 0.75867, saving model to /content/weights_2.best.hdf5\n",
      "Epoch 20/50\n",
      "61178/61178 [==============================] - 14s 233us/step - loss: 0.3708 - auc: 0.7623 - val_loss: 0.3785 - val_auc: 0.7572\n",
      "\n",
      "Epoch 00020: val_auc did not improve from 0.75867\n",
      "Epoch 21/50\n",
      "61178/61178 [==============================] - 14s 233us/step - loss: 0.3685 - auc: 0.7682 - val_loss: 0.3754 - val_auc: 0.7580\n",
      "\n",
      "Epoch 00021: val_auc did not improve from 0.75867\n",
      "Epoch 22/50\n",
      "61178/61178 [==============================] - 14s 233us/step - loss: 0.3668 - auc: 0.7710 - val_loss: 0.3755 - val_auc: 0.7556\n",
      "\n",
      "Epoch 00022: val_auc did not improve from 0.75867\n",
      "Epoch 23/50\n",
      "61178/61178 [==============================] - 14s 233us/step - loss: 0.3617 - auc: 0.7789 - val_loss: 0.3761 - val_auc: 0.7589\n",
      "\n",
      "Epoch 00023: val_auc improved from 0.75867 to 0.75888, saving model to /content/weights_2.best.hdf5\n",
      "Epoch 24/50\n",
      "61178/61178 [==============================] - 14s 232us/step - loss: 0.3590 - auc: 0.7810 - val_loss: 0.3782 - val_auc: 0.7523\n",
      "\n",
      "Epoch 00024: val_auc did not improve from 0.75888\n",
      "Epoch 25/50\n",
      "61178/61178 [==============================] - 14s 232us/step - loss: 0.3591 - auc: 0.7834 - val_loss: 0.3746 - val_auc: 0.7555\n",
      "\n",
      "Epoch 00025: val_auc did not improve from 0.75888\n",
      "Epoch 26/50\n",
      "61178/61178 [==============================] - 14s 233us/step - loss: 0.3560 - auc: 0.7888 - val_loss: 0.3749 - val_auc: 0.7563\n",
      "\n",
      "Epoch 00026: val_auc did not improve from 0.75888\n",
      "Epoch 27/50\n",
      "61178/61178 [==============================] - 14s 233us/step - loss: 0.3571 - auc: 0.7845 - val_loss: 0.3768 - val_auc: 0.7574\n",
      "\n",
      "Epoch 00027: val_auc did not improve from 0.75888\n",
      "Epoch 28/50\n",
      "61178/61178 [==============================] - 14s 232us/step - loss: 0.3535 - auc: 0.7899 - val_loss: 0.3773 - val_auc: 0.7570\n",
      "\n",
      "Epoch 00028: val_auc did not improve from 0.75888\n",
      "Epoch 29/50\n",
      "61178/61178 [==============================] - 14s 232us/step - loss: 0.3500 - auc: 0.7927 - val_loss: 0.3815 - val_auc: 0.7572\n",
      "\n",
      "Epoch 00029: val_auc did not improve from 0.75888\n",
      "Epoch 30/50\n",
      "61178/61178 [==============================] - 14s 232us/step - loss: 0.3483 - auc: 0.7990 - val_loss: 0.3787 - val_auc: 0.7550\n",
      "\n",
      "Epoch 00030: val_auc did not improve from 0.75888\n",
      "Epoch 31/50\n",
      "61178/61178 [==============================] - 14s 233us/step - loss: 0.3463 - auc: 0.8018 - val_loss: 0.3756 - val_auc: 0.7549\n",
      "\n",
      "Epoch 00031: val_auc did not improve from 0.75888\n",
      "Epoch 32/50\n",
      "61178/61178 [==============================] - 14s 232us/step - loss: 0.3432 - auc: 0.8071 - val_loss: 0.3789 - val_auc: 0.7502\n",
      "\n",
      "Epoch 00032: val_auc did not improve from 0.75888\n",
      "Epoch 33/50\n",
      "61178/61178 [==============================] - 14s 233us/step - loss: 0.3394 - auc: 0.8102 - val_loss: 0.3792 - val_auc: 0.7504\n",
      "\n",
      "Epoch 00033: val_auc did not improve from 0.75888\n",
      "Epoch 34/50\n",
      "61178/61178 [==============================] - 14s 233us/step - loss: 0.3380 - auc: 0.8118 - val_loss: 0.3811 - val_auc: 0.7513\n",
      "\n",
      "Epoch 00034: val_auc did not improve from 0.75888\n",
      "Epoch 35/50\n",
      "61178/61178 [==============================] - 14s 232us/step - loss: 0.3376 - auc: 0.8149 - val_loss: 0.3868 - val_auc: 0.7443\n",
      "\n",
      "Epoch 00035: val_auc did not improve from 0.75888\n",
      "Epoch 36/50\n",
      "61178/61178 [==============================] - 14s 233us/step - loss: 0.3342 - auc: 0.8167 - val_loss: 0.3831 - val_auc: 0.7500\n",
      "\n",
      "Epoch 00036: val_auc did not improve from 0.75888\n",
      "Epoch 37/50\n",
      "61178/61178 [==============================] - 14s 233us/step - loss: 0.3319 - auc: 0.8226 - val_loss: 0.3850 - val_auc: 0.7529\n",
      "\n",
      "Epoch 00037: val_auc did not improve from 0.75888\n",
      "Epoch 38/50\n",
      "61178/61178 [==============================] - 14s 232us/step - loss: 0.3281 - auc: 0.8281 - val_loss: 0.3844 - val_auc: 0.7434\n",
      "\n",
      "Epoch 00038: val_auc did not improve from 0.75888\n",
      "Epoch 39/50\n",
      "61178/61178 [==============================] - 14s 232us/step - loss: 0.3255 - auc: 0.8297 - val_loss: 0.3847 - val_auc: 0.7437\n",
      "\n",
      "Epoch 00039: val_auc did not improve from 0.75888\n",
      "Epoch 40/50\n",
      "61178/61178 [==============================] - 14s 232us/step - loss: 0.3253 - auc: 0.8299 - val_loss: 0.3892 - val_auc: 0.7433\n",
      "\n",
      "Epoch 00040: val_auc did not improve from 0.75888\n",
      "Epoch 41/50\n",
      "61178/61178 [==============================] - 14s 232us/step - loss: 0.3206 - auc: 0.8366 - val_loss: 0.3991 - val_auc: 0.7368\n",
      "\n",
      "Epoch 00041: val_auc did not improve from 0.75888\n",
      "Epoch 42/50\n",
      "61178/61178 [==============================] - 14s 231us/step - loss: 0.3173 - auc: 0.8399 - val_loss: 0.4012 - val_auc: 0.7401\n",
      "\n",
      "Epoch 00042: val_auc did not improve from 0.75888\n",
      "Epoch 43/50\n",
      "61178/61178 [==============================] - 14s 231us/step - loss: 0.3155 - auc: 0.8432 - val_loss: 0.3967 - val_auc: 0.7372\n",
      "\n",
      "Epoch 00043: val_auc did not improve from 0.75888\n",
      "Epoch 44/50\n",
      "61178/61178 [==============================] - 14s 232us/step - loss: 0.3144 - auc: 0.8444 - val_loss: 0.4040 - val_auc: 0.7372\n",
      "\n",
      "Epoch 00044: val_auc did not improve from 0.75888\n",
      "Epoch 45/50\n",
      "61178/61178 [==============================] - 14s 232us/step - loss: 0.3077 - auc: 0.8518 - val_loss: 0.4055 - val_auc: 0.7330\n",
      "\n",
      "Epoch 00045: val_auc did not improve from 0.75888\n",
      "Epoch 46/50\n",
      "61178/61178 [==============================] - 14s 231us/step - loss: 0.3062 - auc: 0.8550 - val_loss: 0.4099 - val_auc: 0.7310\n",
      "\n",
      "Epoch 00046: val_auc did not improve from 0.75888\n",
      "Epoch 47/50\n",
      "61178/61178 [==============================] - 14s 232us/step - loss: 0.3056 - auc: 0.8551 - val_loss: 0.4110 - val_auc: 0.7321\n",
      "\n",
      "Epoch 00047: val_auc did not improve from 0.75888\n",
      "Epoch 48/50\n",
      "61178/61178 [==============================] - 14s 232us/step - loss: 0.3030 - auc: 0.8586 - val_loss: 0.4090 - val_auc: 0.7344\n",
      "\n",
      "Epoch 00048: val_auc did not improve from 0.75888\n",
      "Epoch 49/50\n",
      "61178/61178 [==============================] - 14s 231us/step - loss: 0.2991 - auc: 0.8598 - val_loss: 0.4229 - val_auc: 0.7252\n",
      "\n",
      "Epoch 00049: val_auc did not improve from 0.75888\n",
      "Epoch 50/50\n",
      "61178/61178 [==============================] - 14s 232us/step - loss: 0.2977 - auc: 0.8638 - val_loss: 0.4099 - val_auc: 0.7293\n",
      "\n",
      "Epoch 00050: val_auc did not improve from 0.75888\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f4700728860>"
      ]
     },
     "execution_count": 114,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model fitting\n",
    "#https://machinelearningmastery.com/check-point-deep-learning-models-keras/\n",
    "filepath=\"/content/weights_2.best.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_auc', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint,tensorboard]\n",
    "model.run_eagerly=True\n",
    "model.fit([X_train,X_train_school_state,X_train_project_grade,X_train_project_cat,X_train_project_subcat,\n",
    "           X_train_teacher_prefix,train['remaining_input']], y_train, nb_epoch=50,verbose=1,batch_size=256,\n",
    "          validation_data=([X_cv,X_cv_school_state,X_cv_project_grade,X_cv_project_cat,X_cv_project_subcat,\n",
    "           X_cv_teacher_prefix,cv['remaining_input']]  , y_cv),callbacks =callbacks_list )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h213t8ZTBjym"
   },
   "outputs": [],
   "source": [
    "#input 1\n",
    "input1 = Input(shape=(250,))\n",
    "x1 = Embedding(input_dim=56981,output_dim= 300,weights=[embedding_mat(feature_names[5])],trainable=False)(input1)\n",
    "x1 = SpatialDropout1D(0.3)(x1)\n",
    "x1 = CuDNNLSTM(128,return_sequences=True)(x1)\n",
    "x1 = Flatten()(x1)\n",
    "\n",
    "#input 2\n",
    "input2 = Input(shape=(1,))\n",
    "x2 = Embedding(input_dim= 52,output_dim= 2)(input2)\n",
    "#x2 = SpatialDropout1D(0.3)(x2)\n",
    "x2 = Flatten()(x2)\n",
    "\n",
    "#input 3\n",
    "input3 = Input(shape=(1,))\n",
    "x3 = Embedding(input_dim= 5,output_dim= 2)(input3)\n",
    "#x3 = SpatialDropout1D(0.3)(x3)\n",
    "x3 = Flatten()(x3)\n",
    "\n",
    "#input 4\n",
    "input4 = Input(shape=(1,))\n",
    "x4 = Embedding(input_dim=50,output_dim= 2)(input4)\n",
    "#x4 = SpatialDropout1D(0.3)(x4)\n",
    "x4 = Flatten()(x4)\n",
    "\n",
    "#input 5\n",
    "input5 = Input(shape=(1,))\n",
    "x5 = Embedding(input_dim= 385,output_dim= 50)(input5)\n",
    "#x5 = SpatialDropout1D(0.3)(x5)\n",
    "x5 = Flatten()(x5)\n",
    "\n",
    "#input 6\n",
    "input6 = Input(shape=(1,))\n",
    "x6 = Embedding(input_dim= 6,output_dim= 5)(input6)\n",
    "#x6 = SpatialDropout1D(0.3)(x6)\n",
    "x6 = Flatten()(x6)\n",
    "\n",
    "#input 7\n",
    "input7 = Input(shape=(1,))\n",
    "x7 = Dense(16,activation='relu',kernel_initializer=he_normal(),kernel_regularizer=l2(0.0001))(input7)\n",
    "#x7 = Flatten()(x7)\n",
    "#merging all the inputs \n",
    "concat = concatenate([x1,x2,x3,x4,x5,x6,x7])\n",
    "#x = BatchNormalization()(concat)\n",
    "\n",
    "x = Dense(128,activation='relu',kernel_initializer=he_normal(),kernel_regularizer=l2(0.0001))(concat)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(64,activation='relu',kernel_initializer=he_normal(),kernel_regularizer=l2(0.0001))(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dense(32,activation='relu',kernel_initializer=he_normal(),kernel_regularizer=l2(0.0001))(x)\n",
    "x = Dropout(0.5)(x)\n",
    "output = Dense(2, activation = 'softmax')(x)\n",
    " \n",
    "# create model with seven inputs\n",
    "model = Model([input1,input2,input3,input4,input5,input6,input7], output)\n",
    "model.load_weights(\"weights_2.best.hdf5\")\n",
    "model.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.Adam(lr=0.0006,decay = 1e-4),metrics=[auc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "id": "d-aO12-3Bpr0",
    "outputId": "25d2eef9-8926-45d4-8fa5-03dda5b2e887"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Auc for test data: 0.763\n",
      "Auc for CV data: 0.758\n",
      "Auc for train data: 0.814\n"
     ]
    }
   ],
   "source": [
    "print(\"Auc for test data: %0.3f\"%roc_auc_score(y_test,model.predict([X_test,X_test_school_state,X_test_project_grade,X_test_project_cat,X_test_project_subcat,\n",
    "          X_test_teacher_prefix,test['remaining_input']])))\n",
    "print(\"Auc for CV data: %0.3f\"%roc_auc_score(y_cv,model.predict([X_cv,X_cv_school_state,X_cv_project_grade,X_cv_project_cat,X_cv_project_subcat,\n",
    "           X_cv_teacher_prefix,cv['remaining_input']])))\n",
    "print(\"Auc for train data: %0.3f\"%roc_auc_score(y_train,model.predict([X_train,X_train_school_state,X_train_project_grade,X_train_project_cat,X_train_project_subcat,\n",
    "           X_train_teacher_prefix,train['remaining_input']])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](M2_1.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](M2_1_val.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a91NLouUpvXV"
   },
   "source": [
    "# Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 441
    },
    "colab_type": "code",
    "id": "7vK3oNz6p2eP",
    "outputId": "830ea583-6ee6-462d-9b48-3d6a555dcb76"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>teacher_id</th>\n",
       "      <th>teacher_prefix</th>\n",
       "      <th>school_state</th>\n",
       "      <th>project_submitted_datetime</th>\n",
       "      <th>project_grade_category</th>\n",
       "      <th>project_subject_categories</th>\n",
       "      <th>project_subject_subcategories</th>\n",
       "      <th>project_title</th>\n",
       "      <th>project_essay_1</th>\n",
       "      <th>project_essay_2</th>\n",
       "      <th>project_essay_3</th>\n",
       "      <th>project_essay_4</th>\n",
       "      <th>project_resource_summary</th>\n",
       "      <th>teacher_number_of_previously_posted_projects</th>\n",
       "      <th>project_is_approved</th>\n",
       "      <th>presence_of_the_numerical_digits</th>\n",
       "      <th>essay</th>\n",
       "      <th>price</th>\n",
       "      <th>quantity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>p253737</td>\n",
       "      <td>c90749f5d961ff158d4b4d1e7dc665fc</td>\n",
       "      <td>mrs</td>\n",
       "      <td>in</td>\n",
       "      <td>2016-12-05 13:43:57</td>\n",
       "      <td>grades_prek_2</td>\n",
       "      <td>literacy_language</td>\n",
       "      <td>esl_literacy</td>\n",
       "      <td>educational support english learners home</td>\n",
       "      <td>My students are English learners that are work...</td>\n",
       "      <td>\\\"The limits of your language are the limits o...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>My students need opportunities to practice beg...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>students english learners working english seco...</td>\n",
       "      <td>154.60</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>p258326</td>\n",
       "      <td>897464ce9ddc600bced1151f324dd63a</td>\n",
       "      <td>mr</td>\n",
       "      <td>fl</td>\n",
       "      <td>2016-10-25 09:22:10</td>\n",
       "      <td>grades_6_8</td>\n",
       "      <td>history_civics_health_sports</td>\n",
       "      <td>civics_government_teamsports</td>\n",
       "      <td>wanted projector hungry learners</td>\n",
       "      <td>Our students arrive to our school eager to lea...</td>\n",
       "      <td>The projector we need for our school is very c...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>My students need a projector to help with view...</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>students arrive school eager learn polite gene...</td>\n",
       "      <td>299.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>p182444</td>\n",
       "      <td>3465aaf82da834c0582ebd0ef8040ca0</td>\n",
       "      <td>ms</td>\n",
       "      <td>az</td>\n",
       "      <td>2016-08-31 12:03:56</td>\n",
       "      <td>grades_6_8</td>\n",
       "      <td>health_sports</td>\n",
       "      <td>health_wellness_teamsports</td>\n",
       "      <td>soccer equipment awesome middle school students</td>\n",
       "      <td>\\r\\n\\\"True champions aren't always the ones th...</td>\n",
       "      <td>The students on the campus come to school know...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>My students need shine guards, athletic socks,...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>true champions not always ones win guts mia ha...</td>\n",
       "      <td>516.85</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0       id  ...   price quantity\n",
       "0           0  p253737  ...  154.60       23\n",
       "1           1  p258326  ...  299.00        1\n",
       "2           2  p182444  ...  516.85       22\n",
       "\n",
       "[3 rows x 21 columns]"
      ]
     },
     "execution_count": 119,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Reading the dataset\n",
    "project_data = pd.read_csv('processed_train_data.csv')\n",
    "project_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JgvkjDlBqOt8"
   },
   "outputs": [],
   "source": [
    "# adding feature teacher number of previously posted project, presence of numerical digits, price and quantity\n",
    "project_data.drop(['Unnamed: 0'], axis =1 , inplace = True)\n",
    "class_label = project_data['project_is_approved']\n",
    "project_data['remaining_input'] = project_data['teacher_number_of_previously_posted_projects']  +\\\n",
    "                                    project_data['presence_of_the_numerical_digits']  + \\\n",
    "                                    project_data['price'] + project_data['quantity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mvw5dxjwqQ3k"
   },
   "outputs": [],
   "source": [
    "project_data['total_txt'] = project_data['project_title'] + ' ' + project_data['essay'] + ' ' + project_data['project_resource_summary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SC40y4nyqU-T"
   },
   "outputs": [],
   "source": [
    "project_data.replace(to_replace=np.NaN, value= str('nan'),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 167
    },
    "colab_type": "code",
    "id": "34NcO3HJqY3z",
    "outputId": "632ecbf6-e140-42aa-a51f-84f93e3a64a8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'teacher_id', 'teacher_prefix', 'school_state',\n",
       "       'project_submitted_datetime', 'project_grade_category',\n",
       "       'project_subject_categories', 'project_subject_subcategories',\n",
       "       'project_title', 'project_essay_1', 'project_essay_2',\n",
       "       'project_essay_3', 'project_essay_4', 'project_resource_summary',\n",
       "       'teacher_number_of_previously_posted_projects', 'project_is_approved',\n",
       "       'presence_of_the_numerical_digits', 'essay', 'price', 'quantity',\n",
       "       'remaining_input', 'total_txt'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 123,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col = project_data.columns\n",
    "col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yTJ4ZE7Nqcq2"
   },
   "outputs": [],
   "source": [
    "col = ['id','teacher_id','project_submitted_datetime','project_title','project_essay_1', 'project_essay_2',\n",
    "       'project_essay_3', 'project_essay_4','project_resource_summary',\n",
    "       'teacher_number_of_previously_posted_projects', 'project_is_approved','price', 'quantity',\n",
    "        'presence_of_the_numerical_digits','essay']\n",
    "\n",
    "project_data.drop(labels=col,axis =1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zVv1Hdyuqhlc"
   },
   "outputs": [],
   "source": [
    "col = project_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7ChIx34YqnXL"
   },
   "outputs": [],
   "source": [
    "col = ['teacher_prefix', 'school_state', 'project_grade_category',\n",
    "       'project_subject_categories', 'project_subject_subcategories','total_txt',\n",
    "       'remaining_input']\n",
    "project_data = project_data[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9QclFbHqqqwA"
   },
   "outputs": [],
   "source": [
    "def word_ranking(dataframe):\n",
    "    col_names = dataframe.columns\n",
    "    features = []\n",
    "    #performing train test split\n",
    "    train,test,y_train,y_test = train_test_split(dataframe, class_label , stratify = class_label, train_size = 0.7)\n",
    "\n",
    "    train,cv,y_train,y_cv = train_test_split(train,y_train,stratify = y_train,train_size = 0.8)\n",
    "    for col in col_names[5:6]:\n",
    "        print(col)\n",
    "        bag_of_words = CountVectorizer(lowercase= False)\n",
    "        bow_words = bag_of_words.fit_transform(train[col])\n",
    "        print(bow_words.shape)\n",
    "        \n",
    "        #Lets now store the document term matrix in a dictionary.\n",
    "        freqs = bow_words.sum(axis=0).A1\n",
    "        index = freqs.argsort()\n",
    "        words = bag_of_words.get_feature_names()\n",
    "        \n",
    "        \n",
    "\n",
    "        # Assigning Rank to each word based on its freq of occurance. Word with highest freq is assigned rank 1 \n",
    "        word_rank = dict()\n",
    "        rank = 1\n",
    "        for i in index[::-1]:\n",
    "            k = words[i]\n",
    "            word_rank[k] = rank\n",
    "            rank+=1\n",
    "        features.append(word_rank)\n",
    "\n",
    "        #Every word in each review is replaced by its rank\n",
    "        rank = [] # list of all the review with words replaced with rank\n",
    "        for sent in train[col].values:\n",
    "            txt_row = []\n",
    "            for word in sent.split():\n",
    "                if word in word_rank.keys():\n",
    "                    txt_row.append(word_rank[word])\n",
    "                else:\n",
    "                    pass\n",
    "            rank.append(txt_row)\n",
    "        \n",
    "        train[col] = rank\n",
    "        \n",
    "        rank = [] # list of all the review with words replaced with rank\n",
    "        for sent in test[col].values:\n",
    "            txt_row = []\n",
    "            for word in sent.split():\n",
    "                if word in word_rank.keys():\n",
    "                    txt_row.append(word_rank[word])\n",
    "                else:\n",
    "                    pass\n",
    "            rank.append(txt_row)\n",
    "        \n",
    "        test[col] = rank\n",
    "        \n",
    "        rank = [] # list of all the review with words replaced with rank\n",
    "        for sent in cv[col].values:\n",
    "            txt_row = []\n",
    "            for word in sent.split():\n",
    "                if word in word_rank.keys():\n",
    "                    txt_row.append(word_rank[word])\n",
    "                else:\n",
    "                    pass\n",
    "            rank.append(txt_row)\n",
    "        \n",
    "        cv[col] = rank\n",
    "    return train,test,cv,y_train,y_test,y_cv,features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "on4SSqv7q2t5",
    "outputId": "ad696700-7e2e-40f4-f973-6d8da4a07975"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_txt\n",
      "(61178, 56962)\n"
     ]
    }
   ],
   "source": [
    "train,test,cv,y_train,y_test,y_cv,feature_names = word_ranking(project_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "id": "D-Ezt5TGrAH5",
    "outputId": "7823b548-3343-4514-871c-b8570f605af1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the Train dataset:  61178\n",
      "Shape of the Test dataset:  32775\n",
      "Shape of the CV dataset:  15295\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of the Train dataset: \", train.shape[0])\n",
    "print(\"Shape of the Test dataset: \", test.shape[0])\n",
    "print(\"Shape of the CV dataset: \", cv.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "E-gna2DprEPt",
    "outputId": "7ebd12cc-5317-45d7-da3d-08b0ae7a38f4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(61178,)"
      ]
     },
     "execution_count": 130,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "23Mpg76yrII0"
   },
   "outputs": [],
   "source": [
    "#converting class labels to categorical variables\n",
    "from keras.utils import to_categorical\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "y_cv = to_categorical(y_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 385
    },
    "colab_type": "code",
    "id": "tamXWeC7rJt2",
    "outputId": "3e9653bd-0e5e-4832-aa80-eeda4d565c91"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(61178, 250)\n",
      "[    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0   262   817 32910    19\n",
      "     1   102     7   676    24    41    22   162     2    28    45    47\n",
      "   138    93   437   135    47   260    97    66    52    11     1   116\n",
      "     8   522    97   662   157   962    73     6    61     3   267     2\n",
      "   213   572   136   188   380  1027  2225   162    28   882     5   801\n",
      "   149    16   113    72    74   179    62  1042   276     4    72   662\n",
      "   258    29    71    35    94     2    57   153     1    46   270    37\n",
      "   541  1742   306    31    19   119   199   104  4215  1678   434   752\n",
      "  2881  1424   752  2881  1096   208  4227    96     1    46   306    18\n",
      "    19   119     1     7  8392    88    48   645    88  2368  6244  1321\n",
      "  1121   817  2274  2012    88   289     1   142  1016    21    29   823\n",
      "   228    42   253  1214   334    19   119     1    21    37    19  4893\n",
      "    19    37     5   137   199     2   742   181    85    61   250   116\n",
      "   501     6     5    11   154    71     1    18   219   164   262    88\n",
      "  1298  2722   306    31    19   119   197     1    25    27    95  1446\n",
      "   417  2549   429  1551    68  1877   255  1298   289  4215    88   130\n",
      "    29   104  1144   219   176   141   192   503   162    28    72     4\n",
      "    13    10     1     3   104  4215  3004   434   752  3004  1424   752\n",
      "  1096    15  4227     9    15  1742   306    15    18    31]\n"
     ]
    }
   ],
   "source": [
    "max_review_length = 250\n",
    "X_train = pad_sequences(train['total_txt'], maxlen=max_review_length)  #padding zeros at the begining of each review to make max len as 200\n",
    "X_test = pad_sequences(test['total_txt'], maxlen=max_review_length)\n",
    "X_cv = pad_sequences(cv['total_txt'], maxlen=max_review_length)\n",
    "print(X_train.shape)\n",
    "print(X_train[256])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "38eziTusrN1e",
    "outputId": "46c7c1ce-e60f-4933-a97e-a70bc3b449a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(61178, 51)\n"
     ]
    }
   ],
   "source": [
    "token_sc_stat = CountVectorizer()\n",
    "\n",
    "# integer encode the documents\n",
    "school_state_train = token_sc_stat.fit_transform(train['school_state'])\n",
    "school_state_test = token_sc_stat.transform(test['school_state'])\n",
    "school_state_cv = token_sc_stat.transform(cv['school_state'])\n",
    "\n",
    "print(school_state_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "Qd0HNR2brSfj",
    "outputId": "e9e11ebd-eeca-4a5d-f283-65d273429393"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(61178, 4)\n"
     ]
    }
   ],
   "source": [
    "token_grd_cat = CountVectorizer()\n",
    "\n",
    "# integer encode the documents\n",
    "project_grade_train = token_grd_cat.fit_transform(train['project_grade_category'])\n",
    "project_grade_test = token_grd_cat.transform(test['project_grade_category'])\n",
    "project_grade_cv = token_grd_cat.transform(cv['project_grade_category'])\n",
    "\n",
    "print(project_grade_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "Us-uuRJurWWb",
    "outputId": "f0d2e951-884f-460e-c4c0-186f07423b6f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(61178, 50)\n"
     ]
    }
   ],
   "source": [
    "token_prj_cat = CountVectorizer()\n",
    "\n",
    "# integer encode the documents\n",
    "project_cat_train = token_prj_cat.fit_transform(train['project_subject_categories'])\n",
    "project_cat_test = token_prj_cat.transform(test['project_subject_categories'])\n",
    "project_cat_cv = token_prj_cat.transform(cv['project_subject_categories'])\n",
    "\n",
    "\n",
    "print(project_cat_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "vYV6t7cGrav7",
    "outputId": "040df831-745b-4575-efdd-0087c76c2e52"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(61178, 385)\n"
     ]
    }
   ],
   "source": [
    "token_sub_cat = CountVectorizer()\n",
    "\n",
    "# integer encode the documents\n",
    "project_subcat_train = token_sub_cat.fit_transform(train['project_subject_subcategories'])\n",
    "project_subcat_test = token_sub_cat.transform(test['project_subject_subcategories'])\n",
    "project_subcat_cv = token_sub_cat.transform(cv['project_subject_subcategories'])\n",
    "\n",
    "print(project_subcat_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "-03X6kq5rfAd",
    "outputId": "81238767-72ed-459c-a2c3-25dba1120ba8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(61178, 5)\n"
     ]
    }
   ],
   "source": [
    "token_pre = CountVectorizer()\n",
    "\n",
    "# integer encode the documents\n",
    "teacher_prefix_train = token_pre.fit_transform(train['teacher_prefix'])\n",
    "teacher_prefix_test = token_pre.transform(test['teacher_prefix'])\n",
    "teacher_prefix_cv = token_pre.transform(cv['teacher_prefix'])\n",
    "print(teacher_prefix_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hMNrP4WmrkOs"
   },
   "outputs": [],
   "source": [
    "input2_train = hstack((school_state_train,project_grade_train,project_cat_train,project_subcat_train,teacher_prefix_train,train['remaining_input'][:,None]))\n",
    "\n",
    "input2_cv = hstack((school_state_cv,project_grade_cv,project_cat_cv,project_subcat_cv,teacher_prefix_cv,cv['remaining_input'][:,None]))\n",
    "input2_test = hstack((school_state_test,project_grade_test,project_cat_test,project_subcat_test,teacher_prefix_test,test['remaining_input'][:,None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i7jogd6RrrJa"
   },
   "outputs": [],
   "source": [
    "input2_train = hstack((school_state_train,project_grade_train,project_cat_train,project_subcat_train,teacher_prefix_train,train['remaining_input'][:,None]))\n",
    "\n",
    "input2_cv = hstack((school_state_cv,project_grade_cv,project_cat_cv,project_subcat_cv,teacher_prefix_cv,cv['remaining_input'][:,None]))\n",
    "input2_test = hstack((school_state_test,project_grade_test,project_cat_test,project_subcat_test,teacher_prefix_test,test['remaining_input'][:,None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qizAxAE7rxvL"
   },
   "outputs": [],
   "source": [
    "train=input2_train.todense()\n",
    "test = input2_test.todense()\n",
    "cv = input2_cv.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mLtn1VUwrzgX"
   },
   "outputs": [],
   "source": [
    "train = np.resize(train,new_shape=(61178,495,1))\n",
    "test =np.resize(test,new_shape=(32775,495,1))\n",
    "cv = np.resize(cv,new_shape=(15295,495,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "tQ5ErH85r2_q",
    "outputId": "19d20e53-f265-4a0a-b7c9-d98dc511c957"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(61178, 495, 1)"
      ]
     },
     "execution_count": 144,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X50m_MWasoPs"
   },
   "outputs": [],
   "source": [
    "dbfile = open('/content/glove_vectors', 'rb')      \n",
    "db = pickle.load(dbfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VnNNX0ESstI8"
   },
   "outputs": [],
   "source": [
    "#Getting word vectors with 50 dim\n",
    "def embedding_mat(word_index,embedding_dim = 300):\n",
    "    embedding_matrix = np.zeros((len(word_index) + 1, embedding_dim))\n",
    "    for word, i in word_index.items():\n",
    "        embedding_vector = db.get(word)\n",
    "        if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "La-E0UgTtXiU"
   },
   "outputs": [],
   "source": [
    "#AUC score \n",
    "def auc( y_true, y_pred ) :\n",
    "    score = tf.py_func( lambda y_true, y_pred : roc_auc_score( y_true, y_pred).astype('float32'),\n",
    "                        [y_true, y_pred],\n",
    "                        'float32',\n",
    "                        stateful=True,\n",
    "                        name='sklearnAUC' )\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 806
    },
    "colab_type": "code",
    "id": "BbiP4tvstcIc",
    "outputId": "ef6cc20f-0eb0-4cca-9e86-c87193a658af"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0818 12:58:56.542916 139944755865472 nn_ops.py:4224] Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_41 (InputLayer)           (None, 250)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_36 (Embedding)        (None, 250, 300)     17088900    input_41[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_42 (InputLayer)           (None, 495, 1)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_6 (SpatialDro (None, 250, 300)     0           embedding_36[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 493, 64)      256         input_42[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "cu_dnnlstm_6 (CuDNNLSTM)        (None, 250, 256)     571392      spatial_dropout1d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 491, 64)      12352       conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_31 (Flatten)            (None, 64000)        0           cu_dnnlstm_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_32 (Flatten)            (None, 31424)        0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 95424)        0           flatten_31[0][0]                 \n",
      "                                                                 flatten_32[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_26 (Dense)                (None, 300)          28627500    concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, 300)          0           dense_26[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_27 (Dense)                (None, 256)          77056       dropout_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)            (None, 256)          0           dense_27[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 256)          1024        dropout_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_28 (Dense)                (None, 128)          32896       batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)            (None, 128)          0           dense_28[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_29 (Dense)                (None, 2)            258         dropout_18[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 46,411,634\n",
      "Trainable params: 29,322,222\n",
      "Non-trainable params: 17,089,412\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# input 1\n",
    "input1 = Input(batch_shape=(None,250))\n",
    "x1 = Embedding(input_dim=56963,output_dim= 300,weights=[embedding_mat(feature_names[0])],trainable = False)(input1)\n",
    "x1 = SpatialDropout1D(0.3)(x1)\n",
    "x1 = CuDNNLSTM(256,return_sequences=True)(x1)\n",
    "x1 = Flatten()(x1)\n",
    "\n",
    "# input 2\n",
    "input2 = Input(shape=(495,1))\n",
    "x2 = Conv1D(filters=64,kernel_size=3,strides=1)(input2)\n",
    "x2 = Conv1D(filters=64,kernel_size=3,strides=1)(x2)\n",
    "x2 = Flatten()(x2)\n",
    "\n",
    "# merging both the inputs\n",
    "concat = concatenate([x1,x2])\n",
    "x = Dense(300,activation='relu',kernel_initializer=he_normal(),kernel_regularizer=l2(0.0001))(concat)\n",
    "x = Dropout(0.4)(x)\n",
    "x = Dense(256,activation='relu',kernel_initializer=he_normal(),kernel_regularizer=l2(0.0001))(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dense(128,activation='relu',kernel_initializer=he_normal(),kernel_regularizer=l2(0.0001))(x)\n",
    "x = Dropout(0.6)(x)\n",
    "output = Dense(2, activation = 'softmax')(x)\n",
    " \n",
    "# create model with two inputs\n",
    "model = Model([input1,input2], output)\n",
    "tensorboard = TensorBoard(log_dir='logs/{}'.format(time()))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.adam(lr=0.0006,decay = 1e-4), metrics=[auc])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "6ErjUxurz0Kw",
    "outputId": "01cebe78-8919-43ca-af71-5e0e3867264f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 61178 samples, validate on 15295 samples\n",
      "Epoch 1/25\n",
      "61178/61178 [==============================] - 36s 592us/step - loss: 0.7692 - auc: 0.5017 - val_loss: 0.5940 - val_auc: 0.5117\n",
      "\n",
      "Epoch 00001: val_auc improved from -inf to 0.51169, saving model to weights_3.best_copy.hdf5\n",
      "Epoch 2/25\n",
      "61178/61178 [==============================] - 32s 530us/step - loss: 0.6193 - auc: 0.5176 - val_loss: 0.5895 - val_auc: 0.6140\n",
      "\n",
      "Epoch 00002: val_auc improved from 0.51169 to 0.61399, saving model to weights_3.best_copy.hdf5\n",
      "Epoch 3/25\n",
      "61178/61178 [==============================] - 33s 539us/step - loss: 0.5617 - auc: 0.5892 - val_loss: 0.5464 - val_auc: 0.5639\n",
      "\n",
      "Epoch 00003: val_auc did not improve from 0.61399\n",
      "Epoch 4/25\n",
      "61178/61178 [==============================] - 33s 546us/step - loss: 0.5509 - auc: 0.5744 - val_loss: 0.5195 - val_auc: 0.6867\n",
      "\n",
      "Epoch 00004: val_auc improved from 0.61399 to 0.68672, saving model to weights_3.best_copy.hdf5\n",
      "Epoch 5/25\n",
      "61178/61178 [==============================] - 34s 553us/step - loss: 0.5147 - auc: 0.6797 - val_loss: 0.5138 - val_auc: 0.7231\n",
      "\n",
      "Epoch 00005: val_auc improved from 0.68672 to 0.72314, saving model to weights_3.best_copy.hdf5\n",
      "Epoch 6/25\n",
      "61178/61178 [==============================] - 34s 557us/step - loss: 0.5013 - auc: 0.7105 - val_loss: 0.4866 - val_auc: 0.7316\n",
      "\n",
      "Epoch 00006: val_auc improved from 0.72314 to 0.73157, saving model to weights_3.best_copy.hdf5\n",
      "Epoch 7/25\n",
      "61178/61178 [==============================] - 34s 560us/step - loss: 0.4894 - auc: 0.7217 - val_loss: 0.4792 - val_auc: 0.7384\n",
      "\n",
      "Epoch 00007: val_auc improved from 0.73157 to 0.73840, saving model to weights_3.best_copy.hdf5\n",
      "Epoch 8/25\n",
      "61178/61178 [==============================] - 34s 558us/step - loss: 0.4806 - auc: 0.7383 - val_loss: 0.4796 - val_auc: 0.7509\n",
      "\n",
      "Epoch 00008: val_auc improved from 0.73840 to 0.75091, saving model to weights_3.best_copy.hdf5\n",
      "Epoch 9/25\n",
      "61178/61178 [==============================] - 34s 559us/step - loss: 0.4745 - auc: 0.7465 - val_loss: 0.4760 - val_auc: 0.7484\n",
      "\n",
      "Epoch 00009: val_auc did not improve from 0.75091\n",
      "Epoch 10/25\n",
      "61178/61178 [==============================] - 34s 559us/step - loss: 0.4661 - auc: 0.7577 - val_loss: 0.4653 - val_auc: 0.7502\n",
      "\n",
      "Epoch 00010: val_auc did not improve from 0.75091\n",
      "Epoch 11/25\n",
      "61178/61178 [==============================] - 34s 559us/step - loss: 0.4605 - auc: 0.7638 - val_loss: 0.4598 - val_auc: 0.7595\n",
      "\n",
      "Epoch 00011: val_auc improved from 0.75091 to 0.75948, saving model to weights_3.best_copy.hdf5\n",
      "Epoch 12/25\n",
      "61178/61178 [==============================] - 34s 558us/step - loss: 0.4524 - auc: 0.7703 - val_loss: 0.4564 - val_auc: 0.7612\n",
      "\n",
      "Epoch 00012: val_auc improved from 0.75948 to 0.76125, saving model to weights_3.best_copy.hdf5\n",
      "Epoch 13/25\n",
      "61178/61178 [==============================] - 34s 559us/step - loss: 0.4439 - auc: 0.7769 - val_loss: 0.4489 - val_auc: 0.7602\n",
      "\n",
      "Epoch 00013: val_auc did not improve from 0.76125\n",
      "Epoch 14/25\n",
      "61178/61178 [==============================] - 34s 560us/step - loss: 0.4356 - auc: 0.7837 - val_loss: 0.4484 - val_auc: 0.7631\n",
      "\n",
      "Epoch 00014: val_auc improved from 0.76125 to 0.76311, saving model to weights_3.best_copy.hdf5\n",
      "Epoch 15/25\n",
      "61178/61178 [==============================] - 34s 559us/step - loss: 0.4286 - auc: 0.7931 - val_loss: 0.4453 - val_auc: 0.7594\n",
      "\n",
      "Epoch 00015: val_auc did not improve from 0.76311\n",
      "Epoch 16/25\n",
      "61178/61178 [==============================] - 34s 559us/step - loss: 0.4295 - auc: 0.7939 - val_loss: 0.4429 - val_auc: 0.7536\n",
      "\n",
      "Epoch 00016: val_auc did not improve from 0.76311\n",
      "Epoch 17/25\n",
      "61178/61178 [==============================] - 34s 559us/step - loss: 0.4103 - auc: 0.8058 - val_loss: 0.4441 - val_auc: 0.7572\n",
      "\n",
      "Epoch 00017: val_auc did not improve from 0.76311\n",
      "Epoch 18/25\n",
      "61178/61178 [==============================] - 34s 558us/step - loss: 0.4064 - auc: 0.8133 - val_loss: 0.4428 - val_auc: 0.7568\n",
      "\n",
      "Epoch 00018: val_auc did not improve from 0.76311\n",
      "Epoch 19/25\n",
      "61178/61178 [==============================] - 34s 558us/step - loss: 0.4005 - auc: 0.8239 - val_loss: 0.4519 - val_auc: 0.7452\n",
      "\n",
      "Epoch 00019: val_auc did not improve from 0.76311\n",
      "Epoch 20/25\n",
      "61178/61178 [==============================] - 34s 558us/step - loss: 0.3911 - auc: 0.8325 - val_loss: 0.4466 - val_auc: 0.7519\n",
      "\n",
      "Epoch 00020: val_auc did not improve from 0.76311\n",
      "Epoch 21/25\n",
      "61178/61178 [==============================] - 34s 558us/step - loss: 0.3864 - auc: 0.8374 - val_loss: 0.4539 - val_auc: 0.7420\n",
      "\n",
      "Epoch 00021: val_auc did not improve from 0.76311\n",
      "Epoch 22/25\n",
      "61178/61178 [==============================] - 34s 558us/step - loss: 0.3779 - auc: 0.8496 - val_loss: 0.4523 - val_auc: 0.7458\n",
      "\n",
      "Epoch 00022: val_auc did not improve from 0.76311\n",
      "Epoch 23/25\n",
      "61178/61178 [==============================] - 34s 559us/step - loss: 0.3726 - auc: 0.8581 - val_loss: 0.4609 - val_auc: 0.7356\n",
      "\n",
      "Epoch 00023: val_auc did not improve from 0.76311\n",
      "Epoch 24/25\n",
      "61178/61178 [==============================] - 34s 558us/step - loss: 0.3643 - auc: 0.8709 - val_loss: 0.4755 - val_auc: 0.7355\n",
      "\n",
      "Epoch 00024: val_auc did not improve from 0.76311\n",
      "Epoch 25/25\n",
      "61178/61178 [==============================] - 34s 558us/step - loss: 0.3643 - auc: 0.8755 - val_loss: 0.4894 - val_auc: 0.7305\n",
      "\n",
      "Epoch 00025: val_auc did not improve from 0.76311\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f46fff053c8>"
      ]
     },
     "execution_count": 150,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model fitting\n",
    "filepath=\"weights_3.best_copy.hdf5\"\n",
    "model.run_eagerly=True\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_auc', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint,tensorboard]\n",
    "#my_callbacks = [EarlyStopping(monitor='auc', patience=300, verbose=1, mode='max')]\n",
    "model.fit([X_train,train], y_train, nb_epoch=25,verbose=1,batch_size=256,validation_data=([X_cv,\n",
    "        cv], y_cv),callbacks = callbacks_list,class_weight = \"balanced\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "h3gCSAZO3jNR",
    "outputId": "3e344a21-6ace-4da5-a380-6bca61aeace1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0818 13:16:01.463398 139944755865472 nn_ops.py:4224] Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"
     ]
    }
   ],
   "source": [
    "# input 1\n",
    "input1 = Input(batch_shape=(None,250))\n",
    "x1 = Embedding(input_dim=56963,output_dim= 300,weights=[embedding_mat(feature_names[0])],trainable = False)(input1)\n",
    "x1 = SpatialDropout1D(0.3)(x1)\n",
    "x1 = CuDNNLSTM(256,return_sequences=True)(x1)\n",
    "x1 = Flatten()(x1)\n",
    "\n",
    "# input 2\n",
    "input2 = Input(shape=(495,1))\n",
    "x2 = Conv1D(filters=64,kernel_size=3,strides=1)(input2)\n",
    "x2 = Conv1D(filters=64,kernel_size=3,strides=1)(x2)\n",
    "x2 = Flatten()(x2)\n",
    "\n",
    "# merging both the inputs\n",
    "concat = concatenate([x1,x2])\n",
    "x = Dense(300,activation='relu',kernel_initializer=he_normal(),kernel_regularizer=l2(0.0001))(concat)\n",
    "x = Dropout(0.4)(x)\n",
    "x = Dense(256,activation='relu',kernel_initializer=he_normal(),kernel_regularizer=l2(0.0001))(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dense(128,activation='relu',kernel_initializer=he_normal(),kernel_regularizer=l2(0.0001))(x)\n",
    "x = Dropout(0.6)(x)\n",
    "output = Dense(2, activation = 'softmax')(x)\n",
    " \n",
    "# create model with two inputs\n",
    "model = Model([input1,input2], output)\n",
    "model.load_weights(\"weights_3.best_copy.hdf5\")\n",
    "model.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.adam(lr=0.0006,decay = 1e-4), metrics=[auc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "id": "kuL8Pg3-3pTX",
    "outputId": "479b8f90-cf8d-47ea-8dae-8f5f6dee0d7c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Auc for test data: 0.762\n",
      "Auc for CV data: 0.764\n",
      "Auc for train data: 0.817\n"
     ]
    }
   ],
   "source": [
    "print(\"Auc for test data: %0.3f\"%roc_auc_score(y_test,model.predict([X_test,test])))\n",
    "print(\"Auc for CV data: %0.3f\"%roc_auc_score(y_cv,model.predict([X_cv,cv])))\n",
    "print(\"Auc for train data: %0.3f\"%roc_auc_score(y_train,model.predict([X_train,train])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](M3_1.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](M3_1_val.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "LSTM.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
